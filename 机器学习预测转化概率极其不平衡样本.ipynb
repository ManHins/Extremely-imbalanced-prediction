{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba5966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥æ‰€éœ€åº“\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, classification_report, confusion_matrix,\n",
    "    precision_recall_curve, average_precision_score, roc_curve,fbeta_score\n",
    ")\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import shap\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡å­—ä½“\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# è®¾ç½®numpyéšæœºç§å­\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7343be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df = pd.read_parquet('')\n",
    "#æ•°æ®\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc146ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¬¬ä¸€éƒ¨åˆ†ï¼šæ•°æ®é¢„å¤„ç†ä¸ç‰¹å¾å·¥ç¨‹\n",
    "#çœç•¥æ­¤éƒ¨åˆ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a4fb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç‰¹å¾å·¥ç¨‹åï¼Œåˆ†ç¦»æœ€ç»ˆéªŒè¯é›†\n",
    "# ===============================\n",
    "\n",
    "# è·å–æ‰€æœ‰æ­£æ ·æœ¬çš„ç´¢å¼•\n",
    "positive_indices = y[y == 1].index.tolist()\n",
    "print(f\"æ€»æ­£æ ·æœ¬æ•°é‡: {len(positive_indices)}\")\n",
    "# ä»æ­£æ ·æœ¬ä¸­éšæœºé€‰æ‹©30ä¸ªä½œä¸ºæœ€ç»ˆéªŒè¯é›†\n",
    "final_validation_indices = np.random.choice(positive_indices, size=30, replace=False)\n",
    "training_positive_indices = [idx for idx in positive_indices if idx not in final_validation_indices]\n",
    "\n",
    "print(f\"æœ€ç»ˆéªŒè¯é›†æ­£æ ·æœ¬: 30ä¸ª\")\n",
    "print(f\"è®­ç»ƒç”¨æ­£æ ·æœ¬: {len(training_positive_indices)}ä¸ª\")\n",
    "\n",
    "# ä¸ºæœ€ç»ˆéªŒè¯é›†é€‰æ‹©åˆç†æ•°é‡çš„è´Ÿæ ·æœ¬\n",
    "negative_indices = y[y == 0].index.tolist()\n",
    "# é€‰æ‹©åˆç†çš„è´Ÿæ ·æœ¬æ•°é‡ï¼šä½¿ç”¨åŸå§‹æ¯”ä¾‹ï¼Œå³116550ä¸ªè´Ÿæ ·æœ¬\n",
    "final_validation_negative_count = 116550 \n",
    "final_validation_negative_indices = np.random.choice(negative_indices, \n",
    "                                                   size=final_validation_negative_count, \n",
    "                                                   replace=False)\n",
    "\n",
    "print(f\"æœ€ç»ˆéªŒè¯é›†è´Ÿæ ·æœ¬: {final_validation_negative_count}ä¸ª\")\n",
    "print(f\"æœ€ç»ˆéªŒè¯é›†æ€»æ ·æœ¬: {30 + final_validation_negative_count}ä¸ª\")\n",
    "print(f\"æœ€ç»ˆéªŒè¯é›†æ­£è´Ÿæ¯”ä¾‹: 1:{final_validation_negative_count//30}\")\n",
    "\n",
    "# åˆ›å»ºæœ€ç»ˆéªŒè¯é›†\n",
    "final_validation_all_indices = list(final_validation_indices) + list(final_validation_negative_indices)\n",
    "X_final_validation = X.loc[final_validation_all_indices]\n",
    "y_final_validation = y.loc[final_validation_all_indices]\n",
    "\n",
    "# ä»è®­ç»ƒæ•°æ®ä¸­ç§»é™¤æœ€ç»ˆéªŒè¯é›†æ ·æœ¬ï¼ˆä½¿ç”¨æ›´é«˜æ•ˆçš„æ–¹æ³•ï¼‰\n",
    "final_validation_indices_set = set(final_validation_all_indices)\n",
    "remaining_mask = ~X.index.isin(final_validation_all_indices)\n",
    "X_training_pool = X[remaining_mask]\n",
    "y_training_pool = y[remaining_mask]\n",
    "\n",
    "print(f\"æ•°æ®åˆ†å¸ƒ:\")\n",
    "print(f\"è®­ç»ƒæ±  - æ­£æ ·æœ¬: {(y_training_pool == 1).sum()}ä¸ª\")\n",
    "print(f\"è®­ç»ƒæ±  - è´Ÿæ ·æœ¬: {(y_training_pool == 0).sum()}ä¸ª\")\n",
    "print(f\"æœ€ç»ˆéªŒè¯é›† - æ­£æ ·æœ¬: {(y_final_validation == 1).sum()}ä¸ª\")\n",
    "print(f\"æœ€ç»ˆéªŒè¯é›† - è´Ÿæ ·æœ¬: {(y_final_validation == 0).sum()}ä¸ª\")\n",
    "print(f\"æœ€ç»ˆéªŒè¯é›†è½¬åŒ–ç‡: {y_final_validation.mean():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37d56ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¤šé‡æ¬ é‡‡æ ·ç­–ç•¥ï¼šæ„å»ºå¤šä¸ªå¹³è¡¡æ•°æ®é›†è¿›è¡Œäº¤å‰éªŒè¯ï¼ˆä½¿ç”¨119ä¸ªæ­£æ ·æœ¬ï¼‰\n",
    "# =======================================================\n",
    "\n",
    "\n",
    "print(\"å¤šé‡æ¬ é‡‡æ ·å¹³è¡¡æ•°æ®é›†æ„å»ºç­–ç•¥ï¼ˆä¿ç•™30ä¸ªæ­£æ ·æœ¬ä½œä¸ºæœ€ç»ˆéªŒè¯ï¼‰\")\n",
    "print(\"ç­–ç•¥ï¼š119ä¸ªæ­£æ ·æœ¬ + å¤šæ¬¡éšæœºæŠ½å–119ä¸ªè´Ÿæ ·æœ¬\")\n",
    "print(\"æ¨¡å‹ï¼šé€»è¾‘å›å½’ + äº¤å‰éªŒè¯\")\n",
    "print(\"æœ€ç»ˆéªŒè¯ï¼š30ä¸ªæ­£æ ·æœ¬çš„ç‹¬ç«‹æµ‹è¯•é›†\")\n",
    "\n",
    "def create_multiple_balanced_datasets(X, y, n_datasets=100, positive_sample_multiplier=1):\n",
    "    \"\"\"\n",
    "    åˆ›å»ºå¤šä¸ªå¹³è¡¡æ•°æ®é›†\n",
    "    \n",
    "    å‚æ•°:\n",
    "    - X: ç‰¹å¾çŸ©é˜µ\n",
    "    - y: æ ‡ç­¾\n",
    "    - n_datasets: è¦åˆ›å»ºçš„æ•°æ®é›†æ•°é‡\n",
    "    - positive_sample_multiplier: è´Ÿæ ·æœ¬æ•°é‡ç›¸å¯¹äºæ­£æ ·æœ¬çš„å€æ•°ï¼ˆ1è¡¨ç¤º1:1å¹³è¡¡ï¼‰\n",
    "    \"\"\"\n",
    "    \n",
    "    # åˆ†ç¦»æ­£è´Ÿæ ·æœ¬\n",
    "    positive_indices = np.where(y == 1)[0]\n",
    "    negative_indices = np.where(y == 0)[0]\n",
    "    \n",
    "    n_positive = len(positive_indices)\n",
    "    n_negative_per_dataset = n_positive * positive_sample_multiplier\n",
    "    \n",
    "    print(f\"ğŸ“Š æ•°æ®åˆ†å¸ƒ:\")\n",
    "    print(f\"   æ­£æ ·æœ¬æ•°é‡: {n_positive}\")\n",
    "    print(f\"   è´Ÿæ ·æœ¬æ•°é‡: {len(negative_indices)}\")\n",
    "    print(f\"   æ¯ä¸ªæ•°æ®é›†è´Ÿæ ·æœ¬æŠ½å–: {n_negative_per_dataset}\")\n",
    "    print(f\"   å°†åˆ›å»º {n_datasets} ä¸ªå¹³è¡¡æ•°æ®é›†\")\n",
    "    \n",
    "    datasets = []\n",
    "    \n",
    "    # è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿å¯é‡ç°æ€§\n",
    "    #ç¡®ä¿ä¸é‡å¤æŠ½æ ·\n",
    "    for i in range(n_datasets):\n",
    "        # éšæœºæŠ½å–è´Ÿæ ·æœ¬\n",
    "        selected_negative_indices = np.random.choice(\n",
    "            negative_indices, \n",
    "            size=n_negative_per_dataset, \n",
    "            replace=False\n",
    "        )\n",
    "        \n",
    "        # åˆå¹¶æ­£è´Ÿæ ·æœ¬ç´¢å¼•\n",
    "        balanced_indices = np.concatenate([positive_indices, selected_negative_indices])\n",
    "        \n",
    "        # åˆ›å»ºå¹³è¡¡æ•°æ®é›†\n",
    "        X_balanced = X.iloc[balanced_indices]\n",
    "        y_balanced = y.iloc[balanced_indices]\n",
    "        \n",
    "        datasets.append({\n",
    "            'X': X_balanced,\n",
    "            'y': y_balanced,\n",
    "            'indices': balanced_indices,\n",
    "            'dataset_id': i + 1\n",
    "        })\n",
    "        \n",
    "        print(f\"   æ•°æ®é›† {i+1}: {len(y_balanced)} æ ·æœ¬ (æ­£:{sum(y_balanced)}, è´Ÿ:{len(y_balanced)-sum(y_balanced)})\")\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tabulate import tabulate  # å¦‚æœªå®‰è£…ï¼špip install tabulate\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# æ‰§è¡Œå¤šé‡æ¬ é‡‡æ ·ç­–ç•¥ï¼ˆä½¿ç”¨è®­ç»ƒæ± æ•°æ®ï¼‰\n",
    "print(\"å¼€å§‹æ‰§è¡Œå¤šé‡æ¬ é‡‡æ ·ç­–ç•¥...\")\n",
    "\n",
    "# åˆ›å»ºå¤šä¸ªå¹³è¡¡æ•°æ®é›†ï¼ˆä½¿ç”¨å‰©ä½™çš„119ä¸ªæ­£æ ·æœ¬ï¼‰\n",
    "balanced_datasets = create_multiple_balanced_datasets(\n",
    "    X_training_pool, y_training_pool, \n",
    "    n_datasets=10,  # åˆ›å»º100ä¸ªæ•°æ®é›†\n",
    "    positive_sample_multiplier=1  # 1:1 å¹³è¡¡\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c767b42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_logistic_regression_on_datasets(datasets, feature_names):\n",
    "    \"\"\"\n",
    "    åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹å¹¶è¿›è¡Œäº¤å‰éªŒè¯\n",
    "    åŒ…å«L2æ­£åˆ™åŒ–ã€æ¦‚ç‡æ ¡å‡†å’ŒSHAPåˆ†æ\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nğŸ¤– å¼€å§‹è®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # å­˜å‚¨æ‰€æœ‰ç»“æœ\n",
    "    all_results = []\n",
    "    shap_values_all = []\n",
    "    \n",
    "    # L2æ­£åˆ™åŒ–å‚æ•°ç½‘æ ¼\n",
    "    C_values = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "    \n",
    "    for i, dataset in enumerate(datasets):\n",
    "        print(f\"\\n--- è®­ç»ƒæ•°æ®é›† {dataset['dataset_id']} ---\")\n",
    "        \n",
    "        X_train = dataset['X']\n",
    "        y_train = dataset['y']\n",
    "        \n",
    "        # æ ‡å‡†åŒ–ç‰¹å¾\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        \n",
    "        # 1. L2æ­£åˆ™åŒ–å‚æ•°è°ƒä¼˜ - ä»¥F2åˆ†æ•°ä¸ºä¼˜åŒ–ç›®æ ‡\n",
    "        print(\"ğŸ” è¿›è¡ŒL2æ­£åˆ™åŒ–å‚æ•°è°ƒä¼˜ï¼ˆä¼˜åŒ–F2åˆ†æ•°ï¼‰...\")\n",
    "        param_grid = {\n",
    "            'C': C_values,\n",
    "            'l1_ratio': [0],  # çº¯L2æ­£åˆ™åŒ–\n",
    "            'penalty': ['elasticnet'],\n",
    "            'solver': ['saga'],\n",
    "            'max_iter': [1000],\n",
    "            'class_weight': ['balanced']\n",
    "        }\n",
    "        \n",
    "        # å®šä¹‰F2åˆ†æ•°è¯„ä¼°å™¨\n",
    "        from sklearn.metrics import fbeta_score, make_scorer\n",
    "        f2_scorer = make_scorer(fbeta_score, beta=2, zero_division=0)\n",
    "        \n",
    "        base_model = LogisticRegression(random_state=42)\n",
    "        grid_search = GridSearchCV(\n",
    "            base_model, \n",
    "            param_grid, \n",
    "            cv=5, \n",
    "            scoring=f2_scorer,  # ä½¿ç”¨F2åˆ†æ•°ä½œä¸ºä¼˜åŒ–ç›®æ ‡\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        grid_search.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_C = grid_search.best_params_['C']\n",
    "        best_f2_score = grid_search.best_score_\n",
    "        print(f\"æœ€ä½³L2æ­£åˆ™åŒ–å‚æ•° C = {best_C}\")\n",
    "        print(f\"æœ€ä½³F2åˆ†æ•° = {best_f2_score:.4f}\")\n",
    "        \n",
    "        # 2. äº¤å‰éªŒè¯è¯„ä¼°ï¼ˆé‡ç‚¹å…³æ³¨F2åˆ†æ•°ï¼‰\n",
    "        cv_scores = {\n",
    "            'accuracy': cross_val_score(best_model, X_train_scaled, y_train, cv=5, scoring='accuracy'),\n",
    "            'precision': cross_val_score(best_model, X_train_scaled, y_train, cv=5, scoring='precision'),\n",
    "            'recall': cross_val_score(best_model, X_train_scaled, y_train, cv=5, scoring='recall'),\n",
    "            'f1': cross_val_score(best_model, X_train_scaled, y_train, cv=5, scoring='f1'),\n",
    "            'f2': cross_val_score(best_model, X_train_scaled, y_train, cv=5, scoring=f2_scorer),\n",
    "            'roc_auc': cross_val_score(best_model, X_train_scaled, y_train, cv=5, scoring='roc_auc')\n",
    "        }\n",
    "        \n",
    "        # 3. è®­ç»ƒæœ€ç»ˆæ¨¡å‹\n",
    "        best_model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # 4. æ¦‚ç‡æ ¡å‡†\n",
    "        print(\"ğŸ“Š è¿›è¡Œæ¦‚ç‡æ ¡å‡†...\")\n",
    "        # ä½¿ç”¨Platt scalingè¿›è¡Œæ¦‚ç‡æ ¡å‡†\n",
    "        calibrated_model = CalibratedClassifierCV(best_model, method='sigmoid', cv=3)\n",
    "        calibrated_model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # 5. SHAPåˆ†æ\n",
    "        print(\"ğŸ”¬ è¿›è¡ŒSHAPåˆ†æ...\")\n",
    "        try:\n",
    "            # ä¸ºçº¿æ€§æ¨¡å‹åˆ›å»ºSHAP explainer\n",
    "            explainer = shap.LinearExplainer(best_model, X_train_scaled)\n",
    "            shap_values = explainer.shap_values(X_train_scaled)\n",
    "            \n",
    "            # è®¡ç®—ç‰¹å¾é‡è¦æ€§\n",
    "            feature_importance = np.abs(shap_values).mean(axis=0)\n",
    "            \n",
    "            shap_result = {\n",
    "                'explainer': explainer,\n",
    "                'shap_values': shap_values,\n",
    "                'feature_importance': feature_importance,\n",
    "                'feature_names': feature_names\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"SHAPåˆ†æå‡ºé”™: {e}\")\n",
    "            shap_result = None\n",
    "        \n",
    "        # 6. å­˜å‚¨ç»“æœ\n",
    "        result = {\n",
    "            'dataset_id': dataset['dataset_id'],\n",
    "            'model': best_model,\n",
    "            'calibrated_model': calibrated_model,\n",
    "            'scaler': scaler,\n",
    "            'best_C': best_C,\n",
    "            'cv_scores': cv_scores,\n",
    "            'mean_scores': {metric: scores.mean() for metric, scores in cv_scores.items()},\n",
    "            'std_scores': {metric: scores.std() for metric, scores in cv_scores.items()},\n",
    "            'shap_result': shap_result\n",
    "        }\n",
    "        \n",
    "        all_results.append(result)\n",
    "        \n",
    "        # æ‰“å°äº¤å‰éªŒè¯ç»“æœ\n",
    "        print(f\"äº¤å‰éªŒè¯ç»“æœ (5æŠ˜):\")\n",
    "        for metric, scores in cv_scores.items():\n",
    "            print(f\"  {metric:10}: {scores.mean():.4f} (Â±{scores.std():.4f})\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "def plot_calibration_curves(y_true, y_proba_orig, y_proba_calib):\n",
    "    \"\"\"ç»˜åˆ¶æ¦‚ç‡æ ¡å‡†æ›²çº¿\"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # å­å›¾1ï¼šå¯é æ€§å›¾\n",
    "    plt.subplot(1, 3, 1)\n",
    "    fraction_of_positives_orig, mean_predicted_value_orig = calibration_curve(y_true, y_proba_orig, n_bins=10)\n",
    "    fraction_of_positives_calib, mean_predicted_value_calib = calibration_curve(y_true, y_proba_calib, n_bins=10)\n",
    "    \n",
    "    plt.plot(mean_predicted_value_orig, fraction_of_positives_orig, \"s-\", label=\"åŸå§‹æ¨¡å‹\", color='red')\n",
    "    plt.plot(mean_predicted_value_calib, fraction_of_positives_calib, \"o-\", label=\"æ ¡å‡†åæ¨¡å‹\", color='blue')\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", label=\"å®Œç¾æ ¡å‡†\")\n",
    "    plt.xlabel(\"å¹³å‡é¢„æµ‹æ¦‚ç‡\")\n",
    "    plt.ylabel(\"å®é™…æ­£ä¾‹æ¯”ä¾‹\")\n",
    "    plt.title(\"å¯é æ€§å›¾ï¼ˆæ ¡å‡†æ›²çº¿ï¼‰\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # å­å›¾2ï¼šæ¦‚ç‡åˆ†å¸ƒ\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.hist(y_proba_orig, bins=20, alpha=0.7, label='åŸå§‹é¢„æµ‹æ¦‚ç‡', color='red', density=True)\n",
    "    plt.hist(y_proba_calib, bins=20, alpha=0.7, label='æ ¡å‡†åé¢„æµ‹æ¦‚ç‡', color='blue', density=True)\n",
    "    plt.xlabel('é¢„æµ‹æ¦‚ç‡')\n",
    "    plt.ylabel('å¯†åº¦')\n",
    "    plt.title('é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # å­å›¾3ï¼šROCæ›²çº¿\n",
    "    plt.subplot(1, 3, 3)\n",
    "    fpr_orig, tpr_orig, _ = roc_curve(y_true, y_proba_orig)\n",
    "    fpr_calib, tpr_calib, _ = roc_curve(y_true, y_proba_calib)\n",
    "    \n",
    "    plt.plot(fpr_orig, tpr_orig, label=f'åŸå§‹æ¨¡å‹ (AUC = {roc_auc_score(y_true, y_proba_orig):.3f})', color='red')\n",
    "    plt.plot(fpr_calib, tpr_calib, label=f'æ ¡å‡†åæ¨¡å‹ (AUC = {roc_auc_score(y_true, y_proba_calib):.3f})', color='blue')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='éšæœºæ¨¡å‹')\n",
    "    plt.xlabel('å‡æ­£ä¾‹ç‡')\n",
    "    plt.ylabel('çœŸæ­£ä¾‹ç‡')\n",
    "    plt.title('ROCæ›²çº¿')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652f0d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd1d2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒå¤šä¸ªé€»è¾‘å›å½’æ¨¡å‹\n",
    "training_results = train_logistic_regression_on_datasets(balanced_datasets, feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0b347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœ¨æœ€ç»ˆéªŒè¯é›†ä¸Šæµ‹è¯•æ¨¡å‹æ€§èƒ½\n",
    "# =====================================\n",
    "\n",
    "def evaluate_on_final_validation(training_results, X_final_val, y_final_val):\n",
    "    \"\"\"\n",
    "    åœ¨æœ€ç»ˆéªŒè¯é›†ï¼ˆ30ä¸ªæ­£æ ·æœ¬ï¼‰ä¸Šè¯„ä¼°é›†æˆæ¨¡å‹æ€§èƒ½\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"æœ€ç»ˆéªŒè¯é›†è¯„ä¼°ï¼ˆçœŸæ­£çš„æœªè§è¿‡æ•°æ®ï¼‰\")\n",
    "    \n",
    "    # æ”¶é›†æ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹æ¦‚ç‡\n",
    "    all_predictions = []\n",
    "    all_predictions_binary = []\n",
    "    \n",
    "    for result in training_results:\n",
    "        model = result['model']\n",
    "        scaler = result['scaler']\n",
    "        \n",
    "        # æ ‡å‡†åŒ–éªŒè¯é›†\n",
    "        X_val_scaled = scaler.transform(X_final_val)\n",
    "        \n",
    "        # é¢„æµ‹æ¦‚ç‡\n",
    "        y_pred_proba = model.predict_proba(X_val_scaled)[:, 1]\n",
    "        y_pred = model.predict(X_val_scaled)\n",
    "        \n",
    "        all_predictions.append(y_pred_proba)\n",
    "        all_predictions_binary.append(y_pred)\n",
    "    \n",
    "    # é›†æˆé¢„æµ‹ï¼ˆå¹³å‡æ¦‚ç‡ï¼‰\n",
    "    ensemble_proba = np.mean(all_predictions, axis=0)\n",
    "    ensemble_pred = (ensemble_proba >= 0.5).astype(int)\n",
    "    # ä¸åŒé˜ˆå€¼ä¸‹çš„æ€§èƒ½\n",
    "    print(f\"æœ€ç»ˆéªŒè¯é›†åŸºæœ¬ä¿¡æ¯:\")\n",
    "    print(f\"   æ€»æ ·æœ¬æ•°: {len(y_final_val)}\")\n",
    "    print(f\"   æ­£æ ·æœ¬æ•°: {y_final_val.sum()}\")\n",
    "    print(f\"   è´Ÿæ ·æœ¬æ•°: {len(y_final_val) - y_final_val.sum()}\")\n",
    "    print(f\"   è½¬åŒ–ç‡: {y_final_val.mean():.6f}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ æœ€ç»ˆéªŒè¯é›†åœ¨ä¸åŒé˜ˆå€¼ä¸‹çš„æ€§èƒ½:\")\n",
    "    thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    final_threshold_results = []\n",
    "    \n",
    "    print(\"é˜ˆå€¼    ç²¾ç¡®ç‡   å¬å›ç‡    F1åˆ†æ•°   è¯†åˆ«è½¬åŒ–ç”¨æˆ·æ•°  é¢„æµ‹æ­£æ ·æœ¬æ•°\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        pred_at_threshold = (ensemble_proba >= threshold).astype(int)\n",
    "        \n",
    "        precision = precision_score(y_final_val, pred_at_threshold, zero_division=0)\n",
    "        recall = recall_score(y_final_val, pred_at_threshold, zero_division=0)\n",
    "        f1 = f1_score(y_final_val, pred_at_threshold, zero_division=0)\n",
    "        identified_converted = int(recall * y_final_val.sum())\n",
    "        predicted_positive = pred_at_threshold.sum()\n",
    "        \n",
    "        final_threshold_results.append({\n",
    "            'threshold': threshold,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'identified_converted': identified_converted,\n",
    "            'predicted_positive': predicted_positive\n",
    "        })\n",
    "        \n",
    "        print(f\"{threshold:.1f}     {precision:.4f}   {recall:.4f}    {f1:.4f}        {identified_converted}/{y_final_val.sum()}           {predicted_positive}\")\n",
    "    \n",
    "    # æ‰¾åˆ°æœ€ä½³æ€§èƒ½\n",
    "    best_recall_result = max(final_threshold_results, key=lambda x: x['recall'])\n",
    "    best_f1_result = max(final_threshold_results, key=lambda x: x['f1'])\n",
    "    \n",
    "    print(f\"æœ€ç»ˆéªŒè¯é›†æœ€ä½³æ€§èƒ½:\")\n",
    "    print(f\"æœ€é«˜å¬å›ç‡: {best_recall_result['recall']:.4f} (é˜ˆå€¼: {best_recall_result['threshold']:.1f})\")\n",
    "    print(f\"   è¯†åˆ«è½¬åŒ–ç”¨æˆ·: {best_recall_result['identified_converted']}/{y_final_val.sum()}\")\n",
    "    print(f\"   å¯¹åº”ç²¾ç¡®ç‡: {best_recall_result['precision']:.4f}\")\n",
    "    print(f\"   é¢„æµ‹æ­£æ ·æœ¬æ•°: {best_recall_result['predicted_positive']}\")\n",
    "    \n",
    "    print(f\"\\næœ€é«˜F1åˆ†æ•°: {best_f1_result['f1']:.4f} (é˜ˆå€¼: {best_f1_result['threshold']:.1f})\")\n",
    "    print(f\"   å¬å›ç‡: {best_f1_result['recall']:.4f}\")\n",
    "    print(f\"   ç²¾ç¡®ç‡: {best_f1_result['precision']:.4f}\")\n",
    "    print(f\"   è¯†åˆ«è½¬åŒ–ç”¨æˆ·: {best_f1_result['identified_converted']}/{y_final_val.sum()}\")\n",
    "    print(f\"   é¢„æµ‹æ­£æ ·æœ¬æ•°: {best_f1_result['predicted_positive']}\")\n",
    "    \n",
    "    # æ¨¡å‹ç½®ä¿¡åº¦åˆ†æ\n",
    "    print(f\"é¢„æµ‹ç½®ä¿¡åº¦åˆ†æ:\")\n",
    "    positive_probas = ensemble_proba[y_final_val == 1]  # çœŸæ­£è½¬åŒ–ç”¨æˆ·çš„é¢„æµ‹æ¦‚ç‡\n",
    "    negative_probas = ensemble_proba[y_final_val == 0]  # çœŸæ­£æœªè½¬åŒ–ç”¨æˆ·çš„é¢„æµ‹æ¦‚ç‡\n",
    "    \n",
    "    print(f\"çœŸæ­£è½¬åŒ–ç”¨æˆ·çš„å¹³å‡é¢„æµ‹æ¦‚ç‡: {positive_probas.mean():.4f}\")\n",
    "    print(f\"çœŸæ­£è½¬åŒ–ç”¨æˆ·çš„é¢„æµ‹æ¦‚ç‡èŒƒå›´: [{positive_probas.min():.4f}, {positive_probas.max():.4f}]\")\n",
    "    print(f\"çœŸæ­£æœªè½¬åŒ–ç”¨æˆ·çš„å¹³å‡é¢„æµ‹æ¦‚ç‡: {negative_probas.mean():.4f}\")\n",
    "    print(f\"çœŸæ­£æœªè½¬åŒ–ç”¨æˆ·çš„é¢„æµ‹æ¦‚ç‡èŒƒå›´: [{negative_probas.min():.4f}, {negative_probas.max():.4f}]\")\n",
    "    \n",
    "    # ç»˜åˆ¶æ¦‚ç‡åˆ†å¸ƒ\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(positive_probas, bins=20, alpha=0.7, label='è½¬åŒ–ç”¨æˆ·', color='red', density=True)\n",
    "    plt.hist(negative_probas, bins=20, alpha=0.7, label='æœªè½¬åŒ–ç”¨æˆ·', color='blue', density=True)\n",
    "    plt.xlabel('é¢„æµ‹æ¦‚ç‡')\n",
    "    plt.ylabel('å¯†åº¦')\n",
    "    plt.title('æœ€ç»ˆéªŒè¯é›†ï¼šé¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    # æ··æ·†çŸ©é˜µï¼ˆä½¿ç”¨æœ€ä½³F1é˜ˆå€¼ï¼‰\n",
    "    best_pred = (ensemble_proba >= best_f1_result['threshold']).astype(int)\n",
    "    cm = confusion_matrix(y_final_val, best_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'æœ€ç»ˆéªŒè¯é›†æ··æ·†çŸ©é˜µ\\\\n(é˜ˆå€¼={best_f1_result[\"threshold\"]:.1f})')\n",
    "    plt.xlabel('é¢„æµ‹å€¼')\n",
    "    plt.ylabel('å®é™…å€¼')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 5. SHAPåˆ†æ\n",
    "    print(\"ğŸ”¬ è¿›è¡ŒSHAPåˆ†æ...\")\n",
    "    try:\n",
    "        # ä¸ºçº¿æ€§æ¨¡å‹åˆ›å»ºSHAP explainer\n",
    "        explainer = shap.LinearExplainer(result['model'], X_final_val)\n",
    "        shap_values = explainer.shap_values(X_final_val)\n",
    "        \n",
    "        # è®¡ç®—ç‰¹å¾é‡è¦æ€§\n",
    "        feature_importance = np.abs(shap_values).mean(axis=0)\n",
    "        \n",
    "        shap_result = {\n",
    "            'explainer': explainer,\n",
    "            'shap_values': shap_values,\n",
    "            'feature_importance': feature_importance,\n",
    "            'feature_names': feature_names\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"SHAPåˆ†æå‡ºé”™: {e}\")\n",
    "        shap_result = None\n",
    "    print(shap_result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return {\n",
    "        'ensemble_proba': ensemble_proba,\n",
    "        'ensemble_pred': ensemble_pred,\n",
    "        'threshold_results': final_threshold_results,\n",
    "        'best_recall': best_recall_result,\n",
    "        'best_f1': best_f1_result,\n",
    "        'positive_probas': positive_probas,\n",
    "        'negative_probas': negative_probas,\n",
    "        'shap_result': shap_result\n",
    "    }\n",
    "\n",
    "# æ‰§è¡Œæœ€ç»ˆéªŒè¯é›†è¯„ä¼°\n",
    "print(\"å¼€å§‹æœ€ç»ˆéªŒè¯é›†è¯„ä¼°...\")\n",
    "final_validation_results = evaluate_on_final_validation(\n",
    "    training_results, \n",
    "    X_final_validation, \n",
    "    y_final_validation\n",
    ")\n",
    "ensemble_results = final_validation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14acbb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dbf29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full_test = X_final_validation\n",
    "y_full_test = y_final_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902e6a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰ç¼ºå¤±çš„å‡½æ•°å’Œç”Ÿæˆç­–ç•¥ä¿¡æ¯\n",
    "# =====================================\n",
    "\n",
    "def generate_threshold_strategies(ensemble_results):\n",
    "    \"\"\"\n",
    "    ä»é›†æˆç»“æœä¸­ç”Ÿæˆä¸åŒé˜ˆå€¼ç­–ç•¥\n",
    "    \"\"\"\n",
    "    \n",
    "    threshold_results = ensemble_results['threshold_results']\n",
    "    \n",
    "    # æ‰¾åˆ°æœ€ä½³ç­–ç•¥\n",
    "    best_recall = max(threshold_results, key=lambda x: x['recall'])\n",
    "    best_f1 = max(threshold_results, key=lambda x: x['f1'])\n",
    "    best_precision = max(threshold_results, key=lambda x: x['precision'])\n",
    "    \n",
    "    # æ‰¾åˆ°ä¸šåŠ¡å¹³è¡¡ç‚¹ï¼ˆF1åœ¨0.3ä»¥ä¸Šä¸”å¬å›ç‡è¾ƒé«˜ï¼‰\n",
    "    balanced_candidates = [r for r in threshold_results if r['f1'] >= 0.3]\n",
    "    business_balanced = max(balanced_candidates, key=lambda x: x['recall']) if balanced_candidates else best_f1\n",
    "    \n",
    "    strategies = [\n",
    "        ('æœ€é«˜å¬å›ç‡ç­–ç•¥', best_recall),\n",
    "        ('æœ€é«˜F1ç­–ç•¥', best_f1), \n",
    "        ('æœ€é«˜ç²¾ç¡®ç‡ç­–ç•¥', best_precision),\n",
    "        ('ä¸šåŠ¡å¹³è¡¡ç­–ç•¥', business_balanced)\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸ¯ ç”Ÿæˆçš„é˜ˆå€¼ç­–ç•¥:\")\n",
    "    print(\"=\"*60)\n",
    "    for name, strategy in strategies:\n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  é˜ˆå€¼: {strategy['threshold']:.1f}\")\n",
    "        print(f\"  å¬å›ç‡: {strategy['recall']:.4f}\")\n",
    "        print(f\"  ç²¾ç¡®ç‡: {strategy['precision']:.4f}\")\n",
    "        print(f\"  F1åˆ†æ•°: {strategy['f1']:.4f}\")\n",
    "        print(f\"  è¯†åˆ«è½¬åŒ–ç”¨æˆ·: {strategy['identified_converted']}\")\n",
    "        print(\"\")\n",
    "    \n",
    "    return strategies\n",
    "\n",
    "def display_final_confusion_matrices(ensemble_results, y_test):\n",
    "    \"\"\"\n",
    "    æ˜¾ç¤ºå…³é”®é˜ˆå€¼çš„æ··æ·†çŸ©é˜µ\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ğŸ“Š æ˜¾ç¤ºå…³é”®é˜ˆå€¼çš„æ··æ·†çŸ©é˜µ\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # ç”Ÿæˆç­–ç•¥\n",
    "    strategies = generate_threshold_strategies(ensemble_results)\n",
    "    \n",
    "    # é€‰æ‹©å‡ ä¸ªå…³é”®ç­–ç•¥æ˜¾ç¤ºæ··æ·†çŸ©é˜µ\n",
    "    key_strategies = [strategies[0], strategies[1]]  # æœ€é«˜å¬å›ç‡å’Œæœ€é«˜F1\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(key_strategies), figsize=(6*len(key_strategies), 5))\n",
    "    if len(key_strategies) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, (name, strategy) in enumerate(key_strategies):\n",
    "        threshold = strategy['threshold']\n",
    "        predictions = (ensemble_results['ensemble_proba'] >= threshold).astype(int)\n",
    "        \n",
    "        cm = confusion_matrix(y_test, predictions)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i])\n",
    "        axes[i].set_title(f'{name}\\né˜ˆå€¼={threshold:.1f}')\n",
    "        axes[i].set_xlabel('é¢„æµ‹å€¼')\n",
    "        axes[i].set_ylabel('å®é™…å€¼')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return strategies\n",
    "\n",
    "# ç”Ÿæˆç­–ç•¥ä¿¡æ¯\n",
    "print(\"ğŸ”§ ä¿®å¤ç¼ºå¤±çš„å˜é‡...\")\n",
    "final_strategies = generate_threshold_strategies(ensemble_results)\n",
    "\n",
    "print(\"\\nâœ… ç­–ç•¥ä¿¡æ¯ç”Ÿæˆå®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe50914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰é›†æˆé¢„æµ‹å™¨ç±» (ç§»åˆ°æ¨¡å—çº§åˆ«ä»¥æ”¯æŒpickleåºåˆ—åŒ–)\n",
    "# =========================================================\n",
    "\n",
    "class EnsemblePredictor:\n",
    "    \"\"\"\n",
    "    é›†æˆé¢„æµ‹å™¨ç±» - ç”¨äºåŠ è½½å’Œä½¿ç”¨è®­ç»ƒå¥½çš„å¤šä¸ªé€»è¾‘å›å½’æ¨¡å‹\n",
    "    \"\"\"\n",
    "    def __init__(self, models, feature_names, threshold_strategies):\n",
    "        self.models = models  # åŒ…å«modelå’Œscalerçš„åˆ—è¡¨\n",
    "        self.feature_names = feature_names\n",
    "        self.threshold_strategies = threshold_strategies\n",
    "        self.n_models = len(models)\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"é¢„æµ‹æ¦‚ç‡ï¼ˆé›†æˆå¹³å‡ï¼‰\"\"\"\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X[self.feature_names].values\n",
    "        \n",
    "        all_probas = []\n",
    "        for model_info in self.models:\n",
    "            X_scaled = model_info['scaler'].transform(X)\n",
    "            proba = model_info['model'].predict_proba(X_scaled)[:, 1]\n",
    "            all_probas.append(proba)\n",
    "        \n",
    "        return np.mean(all_probas, axis=0)\n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        \"\"\"é¢„æµ‹ç±»åˆ«\"\"\"\n",
    "        probas = self.predict_proba(X)\n",
    "        return (probas >= threshold).astype(int)\n",
    "    \n",
    "    def predict_with_strategy(self, X, strategy_name):\n",
    "        \"\"\"ä½¿ç”¨ç‰¹å®šç­–ç•¥é¢„æµ‹\"\"\"\n",
    "        probas = self.predict_proba(X)\n",
    "        \n",
    "        strategy_thresholds = {\n",
    "            'æœ€é«˜å¬å›ç‡ç­–ç•¥': self.threshold_strategies[0][1]['threshold'],\n",
    "            'æœ€é«˜F1ç­–ç•¥': self.threshold_strategies[1][1]['threshold'],\n",
    "            'æœ€é«˜ç²¾ç¡®ç‡ç­–ç•¥': self.threshold_strategies[2][1]['threshold'],\n",
    "            'ä¸šåŠ¡å¹³è¡¡ç­–ç•¥': self.threshold_strategies[3][1]['threshold']\n",
    "        }\n",
    "        \n",
    "        threshold = strategy_thresholds.get(strategy_name, 0.5)\n",
    "        return (probas >= threshold).astype(int), probas\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        \"\"\"è·å–ç‰¹å¾åç§°\"\"\"\n",
    "        return self.feature_names\n",
    "    \n",
    "    def get_model_info(self):\n",
    "        \"\"\"è·å–æ¨¡å‹ä¿¡æ¯\"\"\"\n",
    "        return {\n",
    "            'n_models': self.n_models,\n",
    "            'feature_names': self.feature_names,\n",
    "            'available_strategies': ['æœ€é«˜å¬å›ç‡ç­–ç•¥', 'æœ€é«˜F1ç­–ç•¥', 'æœ€é«˜ç²¾ç¡®ç‡ç­–ç•¥', 'ä¸šåŠ¡å¹³è¡¡ç­–ç•¥']\n",
    "        }\n",
    "\n",
    "print(\"âœ… EnsemblePredictor ç±»å®šä¹‰å®Œæˆï¼Œæ”¯æŒpickleåºåˆ—åŒ–\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7124104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿®å¤ç‰ˆï¼šä¿å­˜æ¨¡å‹ï¼ˆä½¿ç”¨å…¨å±€EnsemblePredictorç±»ï¼‰\n",
    "# =============================================\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "def save_ensemble_model_fixed(training_results, ensemble_results, feature_names, strategies):\n",
    "    \"\"\"\n",
    "    ä¿å­˜è®­ç»ƒå¥½çš„é›†æˆæ¨¡å‹å’Œç›¸å…³ä¿¡æ¯ï¼ˆä¿®å¤pickleé”™è¯¯ï¼‰\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ’¾ ä¿å­˜æ¨¡å‹...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # åˆ›å»ºä¿å­˜ç›®å½•\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_dir = f\"./saved_models_{timestamp}\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. ä¿å­˜æ‰€æœ‰å•ä¸ªæ¨¡å‹\n",
    "    print(\"ä¿å­˜10ä¸ªå•ç‹¬çš„é€»è¾‘å›å½’æ¨¡å‹...\")\n",
    "    individual_models = {}\n",
    "    for result in training_results:\n",
    "        model_id = result['dataset_id']\n",
    "        model_info = {\n",
    "            'model': result['model'],\n",
    "            'scaler': result['scaler'],\n",
    "            'cv_scores': result['cv_scores'],\n",
    "            'mean_scores': result['mean_scores'],\n",
    "            'std_scores': result['std_scores']\n",
    "        }\n",
    "        \n",
    "        # ä¿å­˜å•ä¸ªæ¨¡å‹\n",
    "        model_filename = f\"{model_dir}/model_{model_id}.pkl\"\n",
    "        joblib.dump(model_info, model_filename)\n",
    "        individual_models[f'model_{model_id}'] = model_filename\n",
    "        print(f\"  âœ… æ¨¡å‹ {model_id} å·²ä¿å­˜: {model_filename}\")\n",
    "    \n",
    "    # 2. ä¿å­˜é›†æˆæ¨¡å‹é¢„æµ‹å™¨ï¼ˆä½¿ç”¨å…¨å±€å®šä¹‰çš„ç±»ï¼‰\n",
    "    print(\"\\\\nä¿å­˜é›†æˆæ¨¡å‹é¢„æµ‹å™¨...\")\n",
    "    \n",
    "    # åˆ›å»ºé›†æˆé¢„æµ‹å™¨ï¼ˆä½¿ç”¨å·²å®šä¹‰çš„å…¨å±€EnsemblePredictorç±»ï¼‰\n",
    "    ensemble_predictor = EnsemblePredictor(\n",
    "        models=[{'model': r['model'], 'scaler': r['scaler']} for r in training_results],\n",
    "        feature_names=feature_names,\n",
    "        threshold_strategies=strategies\n",
    "    )\n",
    "    \n",
    "    # ä¿å­˜é›†æˆé¢„æµ‹å™¨\n",
    "    ensemble_filename = f\"{model_dir}/ensemble_predictor.pkl\"\n",
    "    joblib.dump(ensemble_predictor, ensemble_filename)\n",
    "    print(f\"  âœ… é›†æˆé¢„æµ‹å™¨å·²ä¿å­˜: {ensemble_filename}\")\n",
    "    \n",
    "    # 3. ä¿å­˜æ¨¡å‹å…ƒä¿¡æ¯\n",
    "    print(\"\\\\nä¿å­˜æ¨¡å‹å…ƒä¿¡æ¯...\")\n",
    "    model_metadata = {\n",
    "        'timestamp': timestamp,\n",
    "        'model_type': 'Multiple Undersampling Logistic Regression Ensemble',\n",
    "        'n_models': len(training_results),\n",
    "        'feature_names': feature_names,\n",
    "        'n_features': len(feature_names),\n",
    "        'training_strategy': '149æ­£æ ·æœ¬ + 10æ¬¡éšæœº149è´Ÿæ ·æœ¬',\n",
    "        'ensemble_results': ensemble_results,\n",
    "        'threshold_strategies': {name: result for name, result in strategies},\n",
    "        'individual_model_files': individual_models,\n",
    "        'ensemble_file': ensemble_filename,\n",
    "        'model_directory': model_dir\n",
    "    }\n",
    "    \n",
    "    metadata_filename = f\"{model_dir}/model_metadata.pkl\"\n",
    "    with open(metadata_filename, 'wb') as f:\n",
    "        pickle.dump(model_metadata, f)\n",
    "    print(f\"  âœ… æ¨¡å‹å…ƒä¿¡æ¯å·²ä¿å­˜: {metadata_filename}\")\n",
    "    \n",
    "    # 4. ä¿å­˜ä½¿ç”¨è¯´æ˜\n",
    "    print(\"\\\\nç”Ÿæˆä½¿ç”¨è¯´æ˜...\")\n",
    "    usage_guide = f'''# æ¨¡å‹ä½¿ç”¨æŒ‡å—\n",
    "ä¿å­˜æ—¶é—´: {timestamp}\n",
    "\n",
    "## æ–‡ä»¶è¯´æ˜:\n",
    "- ensemble_predictor.pkl: é›†æˆé¢„æµ‹å™¨ï¼ˆæ¨èä½¿ç”¨ï¼‰\n",
    "- model_1.pkl ~ model_10.pkl: 10ä¸ªå•ç‹¬çš„é€»è¾‘å›å½’æ¨¡å‹\n",
    "- model_metadata.pkl: æ¨¡å‹å…ƒä¿¡æ¯å’Œæ€§èƒ½æ•°æ®\n",
    "\n",
    "## ä½¿ç”¨ç¤ºä¾‹:\n",
    "\n",
    "```python\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# åŠ è½½é›†æˆé¢„æµ‹å™¨\n",
    "ensemble_model = joblib.load('{ensemble_filename}')\n",
    "\n",
    "# å‡†å¤‡æ–°æ•°æ®ï¼ˆç¡®ä¿ç‰¹å¾é¡ºåºä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰\n",
    "# X_new = your_new_data[feature_names]\n",
    "\n",
    "# æ–¹æ³•1: ä½¿ç”¨é»˜è®¤é˜ˆå€¼é¢„æµ‹\n",
    "predictions = ensemble_model.predict(X_new)\n",
    "probabilities = ensemble_model.predict_proba(X_new)\n",
    "\n",
    "# æ–¹æ³•2: ä½¿ç”¨ç‰¹å®šç­–ç•¥é¢„æµ‹\n",
    "predictions, probabilities = ensemble_model.predict_with_strategy(X_new, 'æœ€é«˜å¬å›ç‡ç­–ç•¥')\n",
    "\n",
    "# å¯ç”¨ç­–ç•¥:\n",
    "# - 'æœ€é«˜å¬å›ç‡ç­–ç•¥': æœ€å¤§åŒ–è½¬åŒ–ç”¨æˆ·è¯†åˆ«\n",
    "# - 'æœ€é«˜F1ç­–ç•¥': å¹³è¡¡ç²¾ç¡®ç‡å’Œå¬å›ç‡  \n",
    "# - 'æœ€é«˜ç²¾ç¡®ç‡ç­–ç•¥': æœ€å°åŒ–è¯¯åˆ¤\n",
    "# - 'ä¸šåŠ¡å¹³è¡¡ç­–ç•¥': é€‚ä¸­çš„ä¸šåŠ¡å¹³è¡¡ç‚¹\n",
    "```\n",
    "\n",
    "## æ€§èƒ½æ€»ç»“:\n",
    "'''\n",
    "    \n",
    "    for name, result in strategies:\n",
    "        usage_guide += f\"- {name}: é˜ˆå€¼{result['threshold']:.1f}, å¬å›ç‡{result['recall']:.3f}, ç²¾ç¡®ç‡{result['precision']:.3f}\\\\n\"\n",
    "    \n",
    "    with open(f\"{model_dir}/ä½¿ç”¨æŒ‡å—.txt\", 'w', encoding='utf-8') as f:\n",
    "        f.write(usage_guide)\n",
    "    print(f\"  âœ… ä½¿ç”¨æŒ‡å—å·²ä¿å­˜: {model_dir}/ä½¿ç”¨æŒ‡å—.txt\")\n",
    "    \n",
    "    print(f\"\\\\nğŸ‰ æ‰€æœ‰æ¨¡å‹æ–‡ä»¶å·²ä¿å­˜åˆ°ç›®å½•: {model_dir}\")\n",
    "    print(f\"ğŸ“ ç›®å½•åŒ…å«:\")\n",
    "    for file in os.listdir(model_dir):\n",
    "        file_path = os.path.join(model_dir, file)\n",
    "        file_size = os.path.getsize(file_path) / 1024  # KB\n",
    "        print(f\"   ğŸ“„ {file} ({file_size:.1f} KB)\")\n",
    "    \n",
    "    return model_dir, ensemble_predictor\n",
    "\n",
    "# é‡æ–°æ‰§è¡Œæ¨¡å‹ä¿å­˜ï¼ˆä½¿ç”¨ä¿®å¤ç‰ˆï¼‰\n",
    "print(\"ğŸ”§ ä½¿ç”¨ä¿®å¤ç‰ˆå‡½æ•°é‡æ–°ä¿å­˜æ¨¡å‹...\")\n",
    "\n",
    "# æ˜¾ç¤ºæ··æ·†çŸ©é˜µï¼ˆå¦‚æœè¿˜æ²¡æœ‰æ˜¾ç¤ºï¼‰\n",
    "try:\n",
    "    final_strategies\n",
    "    print(\"âœ… æ··æ·†çŸ©é˜µå·²æ˜¾ç¤º\")\n",
    "except NameError:\n",
    "    print(\"âš ï¸  é‡æ–°ç”Ÿæˆæ··æ·†çŸ©é˜µ...\")\n",
    "    final_strategies = display_final_confusion_matrices(ensemble_results, y_full_test)\n",
    "\n",
    "# ä¿å­˜æ¨¡å‹ï¼ˆä½¿ç”¨ä¿®å¤ç‰ˆå‡½æ•°ï¼‰\n",
    "model_directory_fixed, saved_ensemble_model_fixed = save_ensemble_model_fixed(\n",
    "    training_results, ensemble_results, feature_names, final_strategies\n",
    ")\n",
    "\n",
    "print(f\"\\\\nâœ… æ¨¡å‹ä¿å­˜å®Œæˆï¼ç›®å½•: {model_directory_fixed}\")\n",
    "print(f\"ğŸ‰ ç°åœ¨å¯ä»¥å®‰å…¨åœ°åŠ è½½å’Œä½¿ç”¨æ¨¡å‹äº†ï¼\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70879b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb8bed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–åˆ†æå’Œç»“æœæ±‡æ€»\n",
    "# =======================\n",
    "\n",
    "def plot_comprehensive_analysis(training_results, ensemble_results, y_full_test):\n",
    "    \"\"\"\n",
    "    ç»˜åˆ¶ç»¼åˆåˆ†æå›¾è¡¨\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # 1. äº¤å‰éªŒè¯æ€§èƒ½å¯¹æ¯”\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "    dataset_ids = [result['dataset_id'] for result in training_results]\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        if i < 5:  # åªç»˜åˆ¶å‰5ä¸ªæŒ‡æ ‡\n",
    "            mean_values = [result['mean_scores'][metric] for result in training_results]\n",
    "            std_values = [result['std_scores'][metric] for result in training_results]\n",
    "            \n",
    "            if metric == 'recall':\n",
    "                axes[0, 0].errorbar(dataset_ids, mean_values, yerr=std_values, \n",
    "                                  marker='o', label=metric, linewidth=2, markersize=6)\n",
    "            elif metric == 'precision':\n",
    "                axes[0, 1].errorbar(dataset_ids, mean_values, yerr=std_values, \n",
    "                                  marker='s', label=metric, linewidth=2, markersize=6)\n",
    "            elif metric == 'f1':\n",
    "                axes[0, 2].errorbar(dataset_ids, mean_values, yerr=std_values, \n",
    "                                  marker='^', label=metric, linewidth=2, markersize=6)\n",
    "    \n",
    "    axes[0, 0].set_title('å„æ•°æ®é›†å¬å›ç‡å¯¹æ¯”', fontsize=14)\n",
    "    axes[0, 0].set_xlabel('æ•°æ®é›†ID')\n",
    "    axes[0, 0].set_ylabel('å¬å›ç‡')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    axes[0, 1].set_title('å„æ•°æ®é›†ç²¾ç¡®ç‡å¯¹æ¯”', fontsize=14)\n",
    "    axes[0, 1].set_xlabel('æ•°æ®é›†ID')\n",
    "    axes[0, 1].set_ylabel('ç²¾ç¡®ç‡')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    axes[0, 2].set_title('å„æ•°æ®é›†F1åˆ†æ•°å¯¹æ¯”', fontsize=14)\n",
    "    axes[0, 2].set_xlabel('æ•°æ®é›†ID')\n",
    "    axes[0, 2].set_ylabel('F1åˆ†æ•°')\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    axes[0, 2].legend()\n",
    "    \n",
    "    # 2. é˜ˆå€¼æ€§èƒ½æ›²çº¿\n",
    "    thresholds = [result['threshold'] for result in ensemble_results['threshold_results']]\n",
    "    recalls = [result['recall'] for result in ensemble_results['threshold_results']]\n",
    "    precisions = [result['precision'] for result in ensemble_results['threshold_results']]\n",
    "    f1s = [result['f1'] for result in ensemble_results['threshold_results']]\n",
    "    \n",
    "    axes[1, 0].plot(thresholds, recalls, 'o-', label='å¬å›ç‡', linewidth=2, markersize=6)\n",
    "    axes[1, 0].plot(thresholds, precisions, 's-', label='ç²¾ç¡®ç‡', linewidth=2, markersize=6)\n",
    "    axes[1, 0].plot(thresholds, f1s, '^-', label='F1åˆ†æ•°', linewidth=2, markersize=6)\n",
    "    axes[1, 0].set_xlabel('é¢„æµ‹é˜ˆå€¼')\n",
    "    axes[1, 0].set_ylabel('æ€§èƒ½æŒ‡æ ‡')\n",
    "    axes[1, 0].set_title('é›†æˆæ¨¡å‹é˜ˆå€¼æ€§èƒ½æ›²çº¿', fontsize=14)\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. è½¬åŒ–ç”¨æˆ·è¯†åˆ«æ•°é‡\n",
    "    identified_counts = [result['identified_converted'] for result in ensemble_results['threshold_results']]\n",
    "    total_converted = y_full_test.sum()\n",
    "    \n",
    "    axes[1, 1].bar(range(len(thresholds)), identified_counts, alpha=0.7, color='skyblue')\n",
    "    axes[1, 1].axhline(y=total_converted, color='red', linestyle='--', \n",
    "                      label=f'æ€»è½¬åŒ–ç”¨æˆ·æ•°: {total_converted}')\n",
    "    axes[1, 1].set_xlabel('é˜ˆå€¼ç´¢å¼•')\n",
    "    axes[1, 1].set_ylabel('è¯†åˆ«çš„è½¬åŒ–ç”¨æˆ·æ•°')\n",
    "    axes[1, 1].set_title('ä¸åŒé˜ˆå€¼è¯†åˆ«çš„è½¬åŒ–ç”¨æˆ·æ•°', fontsize=14)\n",
    "    axes[1, 1].set_xticks(range(len(thresholds)))\n",
    "    axes[1, 1].set_xticklabels([f'{t:.1f}' for t in thresholds], rotation=45)\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. æ··æ·†çŸ©é˜µ (æœ€ä½³F1é˜ˆå€¼)\n",
    "    best_f1_idx = np.argmax(f1s)\n",
    "    best_threshold = thresholds[best_f1_idx]\n",
    "    best_predictions = (ensemble_results['ensemble_proba'] >= best_threshold).astype(int)\n",
    "    \n",
    "    cm = confusion_matrix(y_full_test, best_predictions)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 2])\n",
    "    axes[1, 2].set_title(f'æ··æ·†çŸ©é˜µ (é˜ˆå€¼={best_threshold:.1f})', fontsize=14)\n",
    "    axes[1, 2].set_xlabel('é¢„æµ‹å€¼')\n",
    "    axes[1, 2].set_ylabel('å®é™…å€¼')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# æ‰§è¡Œå¯è§†åŒ–å’ŒæŠ¥å‘Šç”Ÿæˆ\n",
    "plot_comprehensive_analysis(training_results, ensemble_results, y_full_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b37c3bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ff245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆåŒ…å«ç½®ä¿¡åº¦è®¡ç®—ï¼‰\n",
    "# ==========================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def analyze_feature_importance_with_confidence(training_results, X_test, y_test, feature_names):\n",
    "    \"\"\"\n",
    "    åˆ†æç‰¹å¾é‡è¦æ€§å¹¶è®¡ç®—ç½®ä¿¡åº¦\n",
    "    \n",
    "    å‚æ•°:\n",
    "    - training_results: è®­ç»ƒç»“æœåˆ—è¡¨\n",
    "    - X_test: æµ‹è¯•ç‰¹å¾\n",
    "    - y_test: æµ‹è¯•æ ‡ç­¾  \n",
    "    - feature_names: ç‰¹å¾åç§°åˆ—è¡¨\n",
    "    \n",
    "    è¿”å›:\n",
    "    - ç‰¹å¾é‡è¦æ€§åˆ†æç»“æœ\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ğŸ” å¼€å§‹ç‰¹å¾é‡è¦æ€§åˆ†æ...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. æ”¶é›†æ‰€æœ‰æ¨¡å‹çš„ç³»æ•°é‡è¦æ€§\n",
    "    coefficients_matrix = []\n",
    "    \n",
    "    for result in training_results:\n",
    "        model = result['model']\n",
    "        # è·å–é€»è¾‘å›å½’ç³»æ•°ï¼ˆç»å¯¹å€¼è¡¨ç¤ºé‡è¦æ€§ï¼‰\n",
    "        coeffs = np.abs(model.coef_[0])\n",
    "        coefficients_matrix.append(coeffs)\n",
    "    \n",
    "    coefficients_matrix = np.array(coefficients_matrix)\n",
    "    \n",
    "    # 2. è®¡ç®—ç³»æ•°é‡è¦æ€§ç»Ÿè®¡\n",
    "    coef_importance = {\n",
    "        'feature': feature_names,\n",
    "        'mean_importance': np.mean(coefficients_matrix, axis=0),\n",
    "        'std_importance': np.std(coefficients_matrix, axis=0),\n",
    "        'min_importance': np.min(coefficients_matrix, axis=0),\n",
    "        'max_importance': np.max(coefficients_matrix, axis=0)\n",
    "    }\n",
    "    \n",
    "    # è®¡ç®—ç½®ä¿¡åŒºé—´ (95%)\n",
    "    confidence_intervals = []\n",
    "    for i in range(len(feature_names)):\n",
    "        feature_coeffs = coefficients_matrix[:, i]\n",
    "        # è®¡ç®—95%ç½®ä¿¡åŒºé—´\n",
    "        ci_lower, ci_upper = stats.t.interval(\n",
    "            confidence=0.95,\n",
    "            df=len(feature_coeffs)-1,\n",
    "            loc=np.mean(feature_coeffs),\n",
    "            scale=stats.sem(feature_coeffs)\n",
    "        )\n",
    "        confidence_intervals.append((ci_lower, ci_upper))\n",
    "    \n",
    "    coef_importance['confidence_interval'] = confidence_intervals\n",
    "    \n",
    "    # 3. è®¡ç®—å˜å¼‚ç³»æ•°ï¼ˆç¨³å®šæ€§æŒ‡æ ‡ï¼‰\n",
    "    cv_scores = coef_importance['std_importance'] / (coef_importance['mean_importance'] + 1e-10)\n",
    "    coef_importance['coefficient_variation'] = cv_scores\n",
    "    \n",
    "    # 4. ä½¿ç”¨ç½®æ¢é‡è¦æ€§éªŒè¯ï¼ˆå–å‰3ä¸ªæ¨¡å‹è¿›è¡Œè®¡ç®—ï¼ŒèŠ‚çœæ—¶é—´ï¼‰\n",
    "    print(\"ğŸ”„ è®¡ç®—ç½®æ¢é‡è¦æ€§ï¼ˆä½¿ç”¨10ä¸ªæ¨¡å‹éªŒè¯ï¼‰...\")\n",
    "    \n",
    "    permutation_scores = []\n",
    "    for i, result in enumerate(training_results[:10]):  # åªç”¨10ä¸ªæ¨¡å‹\n",
    "        model = result['model']\n",
    "        scaler = result['scaler']\n",
    "        \n",
    "        # æ ‡å‡†åŒ–æµ‹è¯•æ•°æ®\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # è®¡ç®—ç½®æ¢é‡è¦æ€§\n",
    "        perm_importance = permutation_importance(\n",
    "            model, X_test_scaled, y_test,\n",
    "            scoring='roc_auc',\n",
    "            n_repeats=5,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        permutation_scores.append(perm_importance.importances_mean)\n",
    "        print(f\"   æ¨¡å‹ {i+1}/10 å®Œæˆ\")\n",
    "    \n",
    "    # è®¡ç®—ç½®æ¢é‡è¦æ€§ç»Ÿè®¡\n",
    "    permutation_matrix = np.array(permutation_scores)\n",
    "    perm_importance = {\n",
    "        'mean_importance': np.mean(permutation_matrix, axis=0),\n",
    "        'std_importance': np.std(permutation_matrix, axis=0)\n",
    "    }\n",
    "    \n",
    "    # 5. åˆ›å»ºç»¼åˆé‡è¦æ€§æ•°æ®æ¡†\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'coef_importance': coef_importance['mean_importance'],\n",
    "        'coef_std': coef_importance['std_importance'],\n",
    "        'coef_cv': coef_importance['coefficient_variation'],\n",
    "        'confidence_lower': [ci[0] for ci in coef_importance['confidence_interval']],\n",
    "        'confidence_upper': [ci[1] for ci in coef_importance['confidence_interval']],\n",
    "        'perm_importance': perm_importance['mean_importance'],\n",
    "        'perm_std': perm_importance['std_importance']\n",
    "    })\n",
    "    \n",
    "    # è®¡ç®—ç»¼åˆé‡è¦æ€§å¾—åˆ†ï¼ˆç³»æ•°é‡è¦æ€§ + ç½®æ¢é‡è¦æ€§çš„æ ‡å‡†åŒ–ç»„åˆï¼‰\n",
    "    coef_norm = (importance_df['coef_importance'] - importance_df['coef_importance'].min()) / \\\n",
    "                (importance_df['coef_importance'].max() - importance_df['coef_importance'].min() + 1e-10)\n",
    "    perm_norm = (importance_df['perm_importance'] - importance_df['perm_importance'].min()) / \\\n",
    "                (importance_df['perm_importance'].max() - importance_df['perm_importance'].min() + 1e-10)\n",
    "    \n",
    "    importance_df['combined_importance'] = (coef_norm + perm_norm) / 2\n",
    "    \n",
    "    # è®¡ç®—ç¨³å®šæ€§å¾—åˆ†ï¼ˆå˜å¼‚ç³»æ•°è¶Šå°ï¼Œç¨³å®šæ€§è¶Šé«˜ï¼‰\n",
    "    importance_df['stability_score'] = 1 / (1 + importance_df['coef_cv'])\n",
    "    \n",
    "    # æŒ‰ç»¼åˆé‡è¦æ€§æ’åº\n",
    "    importance_df = importance_df.sort_values('combined_importance', ascending=False)\n",
    "    \n",
    "    print(\"âœ… ç‰¹å¾é‡è¦æ€§åˆ†æå®Œæˆï¼\")\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "def plot_feature_importance_analysis(importance_df, top_n=20):\n",
    "    \"\"\"\n",
    "    å¯è§†åŒ–ç‰¹å¾é‡è¦æ€§åˆ†æç»“æœ\n",
    "    \"\"\"\n",
    "    \n",
    "    # å–å‰Nä¸ªæœ€é‡è¦çš„ç‰¹å¾\n",
    "    top_features = importance_df.head(top_n)\n",
    "    \n",
    "    # åˆ›å»ºå›¾è¡¨\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "    \n",
    "    # 1. ç³»æ•°é‡è¦æ€§æ’åºï¼ˆå¸¦ç½®ä¿¡åŒºé—´ï¼‰\n",
    "    ax1 = axes[0, 0]\n",
    "    y_pos = np.arange(len(top_features))\n",
    "    \n",
    "    # ç»˜åˆ¶è¯¯å·®æ¡\n",
    "    ax1.barh(y_pos, top_features['coef_importance'], \n",
    "             xerr=[top_features['coef_importance'] - top_features['confidence_lower'],\n",
    "                   top_features['confidence_upper'] - top_features['coef_importance']],\n",
    "             alpha=0.7, capsize=3)\n",
    "    \n",
    "    ax1.set_yticks(y_pos)\n",
    "    ax1.set_yticklabels(top_features['feature'], fontsize=10)\n",
    "    ax1.set_xlabel('ç³»æ•°é‡è¦æ€§ï¼ˆç»å¯¹å€¼ï¼‰')\n",
    "    ax1.set_title(f'å‰{top_n}ä¸ªç‰¹å¾çš„ç³»æ•°é‡è¦æ€§ï¼ˆå¸¦95%ç½®ä¿¡åŒºé—´ï¼‰', fontsize=14, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. ç½®æ¢é‡è¦æ€§\n",
    "    ax2 = axes[0, 1]\n",
    "    y_pos = np.arange(len(top_features))\n",
    "    \n",
    "    bars = ax2.barh(y_pos, top_features['perm_importance'], \n",
    "                    xerr=top_features['perm_std'],\n",
    "                    alpha=0.7, capsize=3, color='orange')\n",
    "    \n",
    "    ax2.set_yticks(y_pos)\n",
    "    ax2.set_yticklabels(top_features['feature'], fontsize=10)\n",
    "    ax2.set_xlabel('ç½®æ¢é‡è¦æ€§ï¼ˆROC AUCæŸå¤±ï¼‰')\n",
    "    ax2.set_title(f'å‰{top_n}ä¸ªç‰¹å¾çš„ç½®æ¢é‡è¦æ€§', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. ç»¼åˆé‡è¦æ€§å¾—åˆ†\n",
    "    ax3 = axes[1, 0]\n",
    "    \n",
    "    # ä½¿ç”¨é¢œè‰²è¡¨ç¤ºç¨³å®šæ€§\n",
    "    colors = plt.cm.RdYlGn(top_features['stability_score'])\n",
    "    bars = ax3.barh(y_pos, top_features['combined_importance'], color=colors, alpha=0.8)\n",
    "    \n",
    "    ax3.set_yticks(y_pos)\n",
    "    ax3.set_yticklabels(top_features['feature'], fontsize=10)\n",
    "    ax3.set_xlabel('ç»¼åˆé‡è¦æ€§å¾—åˆ†')\n",
    "    ax3.set_title(f'å‰{top_n}ä¸ªç‰¹å¾çš„ç»¼åˆé‡è¦æ€§å¾—åˆ†\\\\nï¼ˆé¢œè‰²æ·±æµ…è¡¨ç¤ºç¨³å®šæ€§ï¼‰', fontsize=14, fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # æ·»åŠ é¢œè‰²æ¡\n",
    "    sm = plt.cm.ScalarMappable(cmap=plt.cm.RdYlGn, \n",
    "                              norm=plt.Normalize(vmin=top_features['stability_score'].min(), \n",
    "                                               vmax=top_features['stability_score'].max()))\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax3)\n",
    "    cbar.set_label('ç¨³å®šæ€§å¾—åˆ†')\n",
    "    \n",
    "    # 4. é‡è¦æ€§ç›¸å…³æ€§åˆ†æ\n",
    "    ax4 = axes[1, 1]\n",
    "    \n",
    "    # æ•£ç‚¹å›¾ï¼šç³»æ•°é‡è¦æ€§ vs ç½®æ¢é‡è¦æ€§\n",
    "    scatter = ax4.scatter(top_features['coef_importance'], \n",
    "                         top_features['perm_importance'],\n",
    "                         c=top_features['stability_score'],\n",
    "                         s=100, alpha=0.7, cmap='RdYlGn')\n",
    "    \n",
    "    # æ·»åŠ ç‰¹å¾åç§°æ ‡æ³¨ï¼ˆä»…æ˜¾ç¤ºå‰10ä¸ªï¼‰\n",
    "    for i, (idx, row) in enumerate(top_features.head(10).iterrows()):\n",
    "        ax4.annotate(row['feature'], \n",
    "                    (row['coef_importance'], row['perm_importance']),\n",
    "                    xytext=(5, 5), textcoords='offset points',\n",
    "                    fontsize=8, alpha=0.8)\n",
    "    \n",
    "    ax4.set_xlabel('ç³»æ•°é‡è¦æ€§')\n",
    "    ax4.set_ylabel('ç½®æ¢é‡è¦æ€§')\n",
    "    ax4.set_title('é‡è¦æ€§æ–¹æ³•ä¸€è‡´æ€§åˆ†æ', fontsize=14, fontweight='bold')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # è®¡ç®—ç›¸å…³ç³»æ•°\n",
    "    correlation = np.corrcoef(top_features['coef_importance'], \n",
    "                             top_features['perm_importance'])[0, 1]\n",
    "    ax4.text(0.05, 0.95, f'ç›¸å…³ç³»æ•°: {correlation:.3f}', \n",
    "             transform=ax4.transAxes, fontsize=12,\n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "    \n",
    "    plt.colorbar(scatter, ax=ax4, label='ç¨³å®šæ€§å¾—åˆ†')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def generate_feature_importance_report(importance_df):\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆç‰¹å¾é‡è¦æ€§åˆ†ææŠ¥å‘Š\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ¯ ç‰¹å¾é‡è¦æ€§åˆ†ææŠ¥å‘Š\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 1. Top 10 æœ€é‡è¦ç‰¹å¾\n",
    "    print(\"\\\\nğŸ† Top 10 æœ€é‡è¦ç‰¹å¾:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    top_10 = importance_df.head(10)\n",
    "    for i, (idx, row) in enumerate(top_10.iterrows(), 1):\n",
    "        print(f\"{i:2d}. {row['feature']}\")\n",
    "        print(f\"     ç»¼åˆé‡è¦æ€§: {row['combined_importance']:.4f}\")\n",
    "        print(f\"     ç³»æ•°é‡è¦æ€§: {row['coef_importance']:.4f} (Â±{row['coef_std']:.4f})\")\n",
    "        print(f\"     ç½®æ¢é‡è¦æ€§: {row['perm_importance']:.4f} (Â±{row['perm_std']:.4f})\")\n",
    "        print(f\"     ç¨³å®šæ€§å¾—åˆ†: {row['stability_score']:.4f}\")\n",
    "        print(f\"     95%ç½®ä¿¡åŒºé—´: [{row['confidence_lower']:.4f}, {row['confidence_upper']:.4f}]\")\n",
    "        print()\n",
    "    \n",
    "    # 2. ç‰¹å¾åˆ†ç±»åˆ†æ\n",
    "    print(\"\\\\nğŸ“Š ç‰¹å¾åˆ†ç±»åˆ†æ:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # æ ¹æ®ç‰¹å¾åç§°åˆ†ç±»\n",
    "    feature_categories = {\n",
    "        'é€šè¯ç›¸å…³': [],\n",
    "        'è½¬åŒ–æ¨¡å¼': [],\n",
    "        'æ¸ é“ç›¸å…³': [],\n",
    "        'æ—¶é—´ç›¸å…³': [],\n",
    "        'å…¶ä»–': []\n",
    "    }\n",
    "    \n",
    "    for _, row in importance_df.iterrows():\n",
    "        feature = row['feature']\n",
    "        if any(keyword in feature for keyword in ['é€šè¯', 'æ‰“é€š', 'å®Œæ’­', 'æ‹¨æ‰“']):\n",
    "            feature_categories['é€šè¯ç›¸å…³'].append((feature, row['combined_importance']))\n",
    "        elif any(keyword in feature for keyword in ['è½¬åŒ–', 'æ¨¡å¼', 'é«˜']):\n",
    "            feature_categories['è½¬åŒ–æ¨¡å¼'].append((feature, row['combined_importance']))\n",
    "        elif any(keyword in feature for keyword in ['æ¸ é“', 'ç™½åå•']):\n",
    "            feature_categories['æ¸ é“ç›¸å…³'].append((feature, row['combined_importance']))\n",
    "        elif any(keyword in feature for keyword in ['æ—¶æ®µ', 'å·¥ä½œæ—¥', 'å‘¨']):\n",
    "            feature_categories['æ—¶é—´ç›¸å…³'].append((feature, row['combined_importance']))\n",
    "        else:\n",
    "            feature_categories['å…¶ä»–'].append((feature, row['combined_importance']))\n",
    "    \n",
    "    for category, features in feature_categories.items():\n",
    "        if features:\n",
    "            avg_importance = np.mean([imp for _, imp in features])\n",
    "            print(f\"{category}: {len(features)}ä¸ªç‰¹å¾, å¹³å‡é‡è¦æ€§: {avg_importance:.4f}\")\n",
    "            # æ˜¾ç¤ºè¯¥ç±»åˆ«æœ€é‡è¦çš„ç‰¹å¾\n",
    "            top_feature = max(features, key=lambda x: x[1])\n",
    "            print(f\"   æœ€é‡è¦: {top_feature[0]} ({top_feature[1]:.4f})\")\n",
    "    \n",
    "    # 3. ç¨³å®šæ€§åˆ†æ\n",
    "    print(\"\\\\nğŸ“ˆ æ¨¡å‹ç¨³å®šæ€§åˆ†æ:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    high_stability = importance_df[importance_df['stability_score'] > 0.8]\n",
    "    medium_stability = importance_df[(importance_df['stability_score'] > 0.6) & \n",
    "                                   (importance_df['stability_score'] <= 0.8)]\n",
    "    low_stability = importance_df[importance_df['stability_score'] <= 0.6]\n",
    "    \n",
    "    print(f\"é«˜ç¨³å®šæ€§ç‰¹å¾ (>0.8): {len(high_stability)}ä¸ª\")\n",
    "    print(f\"ä¸­ç­‰ç¨³å®šæ€§ç‰¹å¾ (0.6-0.8): {len(medium_stability)}ä¸ª\")\n",
    "    print(f\"ä½ç¨³å®šæ€§ç‰¹å¾ (â‰¤0.6): {len(low_stability)}ä¸ª\")\n",
    "    \n",
    "    if len(low_stability) > 0:\n",
    "        print(f\"\\\\nâš ï¸  ä½ç¨³å®šæ€§ç‰¹å¾:\")\n",
    "        for _, row in low_stability.head(5).iterrows():\n",
    "            print(f\"   {row['feature']}: ç¨³å®šæ€§={row['stability_score']:.3f}\")\n",
    "    \n",
    "    # 4. ç½®ä¿¡åº¦åˆ†æ\n",
    "    print(\"\\\\nğŸ¯ ç½®ä¿¡åº¦åˆ†æ:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # è®¡ç®—ç½®ä¿¡åŒºé—´å®½åº¦\n",
    "    confidence_width = importance_df['confidence_upper'] - importance_df['confidence_lower']\n",
    "    \n",
    "    narrow_ci = importance_df[confidence_width < confidence_width.quantile(0.25)]\n",
    "    wide_ci = importance_df[confidence_width > confidence_width.quantile(0.75)]\n",
    "    \n",
    "    print(f\"é«˜ç½®ä¿¡åº¦ç‰¹å¾ (çª„ç½®ä¿¡åŒºé—´): {len(narrow_ci)}ä¸ª\")\n",
    "    print(f\"ä½ç½®ä¿¡åº¦ç‰¹å¾ (å®½ç½®ä¿¡åŒºé—´): {len(wide_ci)}ä¸ª\")\n",
    "    print(f\"å¹³å‡ç½®ä¿¡åŒºé—´å®½åº¦: {confidence_width.mean():.4f}\")\n",
    "    \n",
    "    # 5. ä¸šåŠ¡è§£é‡Š\n",
    "    print(\"\\\\nğŸ’¼ ä¸šåŠ¡è§£é‡Š:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    top_3 = importance_df.head(3)\n",
    "    print(\"æœ€é‡è¦çš„3ä¸ªç‰¹å¾ä¸šåŠ¡å«ä¹‰:\")\n",
    "    for i, (_, row) in enumerate(top_3.iterrows(), 1):\n",
    "        feature = row['feature']\n",
    "        print(f\"{i}. {feature}\")\n",
    "        \n",
    "        # ç®€å•çš„ä¸šåŠ¡è§£é‡Š\n",
    "        if 'è½¬åŒ–æ¨¡å¼å¾—åˆ†' in feature:\n",
    "            print(\"   â†’ ç»¼åˆè½¬åŒ–è¡Œä¸ºæ¨¡å¼è¯„åˆ†ï¼Œæ˜¯æœ€å¼ºçš„è½¬åŒ–é¢„æµ‹æŒ‡æ ‡\")\n",
    "        elif 'é€šè¯' in feature:\n",
    "            print(\"   â†’ é€šè¯ç›¸å…³è¡Œä¸ºï¼Œåæ˜ å®¢æˆ·å‚ä¸åº¦å’Œå…´è¶£ç¨‹åº¦\")\n",
    "        elif 'æ¸ é“' in feature or 'ç™½åå•' in feature:\n",
    "            print(\"   â†’ å®¢æˆ·æ¥æºæ¸ é“ï¼Œä¸åŒæ¸ é“çš„å®¢æˆ·è½¬åŒ–å€¾å‘ä¸åŒ\")\n",
    "        elif 'AI' in feature or 'äººå·¥' in feature:\n",
    "            print(\"   â†’ å®¢æˆ·æ„å‘è¯„ä¼°ï¼Œç›´æ¥åæ˜ è½¬åŒ–å¯èƒ½æ€§\")\n",
    "        else:\n",
    "            print(\"   â†’ å…¶ä»–é‡è¦çš„å®¢æˆ·è¡Œä¸ºæˆ–å±æ€§ç‰¹å¾\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*80)\n",
    "    print(\"âœ… ç‰¹å¾é‡è¦æ€§åˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆï¼\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "# æ‰§è¡Œç‰¹å¾é‡è¦æ€§åˆ†æ\n",
    "print(\"ğŸš€ å¼€å§‹æ‰§è¡Œç‰¹å¾é‡è¦æ€§åˆ†æ...\")\n",
    "importance_results = analyze_feature_importance_with_confidence(\n",
    "    training_results, \n",
    "    X_full_test, \n",
    "    y_full_test, \n",
    "    feature_names\n",
    ")\n",
    "\n",
    "# å¯è§†åŒ–åˆ†æç»“æœ\n",
    "plot_feature_importance_analysis(importance_results, top_n=20)\n",
    "\n",
    "# ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š\n",
    "final_importance_df = generate_feature_importance_report(importance_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ec69f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿å­˜ç‰¹å¾é‡è¦æ€§ç»“æœ\n",
    "# =======================\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# åˆ›å»ºä¿å­˜ç›®å½•\n",
    "save_dir = \"ç‰¹å¾é‡è¦æ€§åˆ†æç»“æœ\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# ç”Ÿæˆæ—¶é—´æˆ³\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# ä¿å­˜è¯¦ç»†çš„é‡è¦æ€§æ•°æ®\n",
    "importance_file = f\"{save_dir}/ç‰¹å¾é‡è¦æ€§åˆ†æ_{timestamp}.xlsx\"\n",
    "with pd.ExcelWriter(importance_file, engine='openpyxl') as writer:\n",
    "    # ä¿å­˜å®Œæ•´çš„é‡è¦æ€§åˆ†æç»“æœ\n",
    "    final_importance_df.to_excel(writer, sheet_name='ç‰¹å¾é‡è¦æ€§æ’åº', index=False)\n",
    "    \n",
    "    # åˆ›å»ºTop 10æ±‡æ€»\n",
    "    top_10_summary = final_importance_df.head(10)[['feature', 'combined_importance', \n",
    "                                                    'coef_importance', 'perm_importance', \n",
    "                                                    'stability_score']].copy()\n",
    "    top_10_summary.columns = ['ç‰¹å¾åç§°', 'ç»¼åˆé‡è¦æ€§', 'ç³»æ•°é‡è¦æ€§', 'ç½®æ¢é‡è¦æ€§', 'ç¨³å®šæ€§å¾—åˆ†']\n",
    "    top_10_summary.to_excel(writer, sheet_name='Top10ç‰¹å¾æ±‡æ€»', index=False)\n",
    "    \n",
    "    # åˆ›å»ºåˆ†ç±»æ±‡æ€»\n",
    "    feature_categories_summary = []\n",
    "    feature_categories = {\n",
    "        'é€šè¯ç›¸å…³': [],\n",
    "        'è½¬åŒ–æ¨¡å¼': [],\n",
    "        'æ¸ é“ç›¸å…³': [],\n",
    "        'æ—¶é—´ç›¸å…³': [],\n",
    "        'å…¶ä»–': []\n",
    "    }\n",
    "    \n",
    "    for _, row in final_importance_df.iterrows():\n",
    "        feature = row['feature']\n",
    "        if any(keyword in feature for keyword in ['é€šè¯', 'æ‰“é€š', 'å®Œæ’­', 'æ‹¨æ‰“']):\n",
    "            feature_categories['é€šè¯ç›¸å…³'].append(row['combined_importance'])\n",
    "        elif any(keyword in feature for keyword in ['è½¬åŒ–', 'æ¨¡å¼', 'é«˜']):\n",
    "            feature_categories['è½¬åŒ–æ¨¡å¼'].append(row['combined_importance'])\n",
    "        elif any(keyword in feature for keyword in ['æ¸ é“', 'ç™½åå•']):\n",
    "            feature_categories['æ¸ é“ç›¸å…³'].append(row['combined_importance'])\n",
    "        elif any(keyword in feature for keyword in ['æ—¶æ®µ', 'å·¥ä½œæ—¥', 'å‘¨']):\n",
    "            feature_categories['æ—¶é—´ç›¸å…³'].append(row['combined_importance'])\n",
    "        else:\n",
    "            feature_categories['å…¶ä»–'].append(row['combined_importance'])\n",
    "    \n",
    "    for category, importances in feature_categories.items():\n",
    "        if importances:\n",
    "            feature_categories_summary.append({\n",
    "                'ç‰¹å¾ç±»åˆ«': category,\n",
    "                'ç‰¹å¾æ•°é‡': len(importances),\n",
    "                'å¹³å‡é‡è¦æ€§': np.mean(importances),\n",
    "                'æœ€é«˜é‡è¦æ€§': np.max(importances),\n",
    "                'æœ€ä½é‡è¦æ€§': np.min(importances)\n",
    "            })\n",
    "    \n",
    "    category_df = pd.DataFrame(feature_categories_summary)\n",
    "    category_df.to_excel(writer, sheet_name='ç‰¹å¾åˆ†ç±»æ±‡æ€»', index=False)\n",
    "\n",
    "print(f\"\\\\nğŸ’¾ ç‰¹å¾é‡è¦æ€§åˆ†æç»“æœå·²ä¿å­˜åˆ°: {importance_file}\")\n",
    "\n",
    "# åˆ›å»ºç®€åŒ–çš„é‡è¦æ€§å­—å…¸ï¼ˆä¾›å…¶ä»–æ¨¡å—ä½¿ç”¨ï¼‰\n",
    "importance_dict = dict(zip(final_importance_df['feature'], \n",
    "                          final_importance_df['combined_importance']))\n",
    "\n",
    "# æ˜¾ç¤ºä¿å­˜çš„æ–‡ä»¶ä¿¡æ¯\n",
    "print(f\"\\\\nğŸ“‚ ä¿å­˜çš„æ–‡ä»¶åŒ…å«ä»¥ä¸‹å†…å®¹:\")\n",
    "print(f\"   ğŸ“„ ç‰¹å¾é‡è¦æ€§æ’åº: åŒ…å«{len(final_importance_df)}ä¸ªç‰¹å¾çš„å®Œæ•´åˆ†æ\")\n",
    "print(f\"   ğŸ“„ Top10ç‰¹å¾æ±‡æ€»: æœ€é‡è¦çš„10ä¸ªç‰¹å¾è¯¦æƒ…\")  \n",
    "print(f\"   ğŸ“„ ç‰¹å¾åˆ†ç±»æ±‡æ€»: æŒ‰ä¸šåŠ¡ç±»åˆ«å½’ç±»çš„é‡è¦æ€§ç»Ÿè®¡\")\n",
    "\n",
    "# å¿«é€ŸæŸ¥çœ‹Top 5ç‰¹å¾åŠå…¶ç½®ä¿¡åº¦\n",
    "print(f\"\\\\nğŸ† Top 5 ç‰¹å¾é‡è¦æ€§å¿«é€Ÿé¢„è§ˆ:\")\n",
    "print(\"=\" * 70)\n",
    "for i, (_, row) in enumerate(final_importance_df.head(5).iterrows(), 1):\n",
    "    ci_width = row['confidence_upper'] - row['confidence_lower']\n",
    "    print(f\"{i}. {row['feature']}\")\n",
    "    print(f\"   é‡è¦æ€§: {row['combined_importance']:.4f}\")\n",
    "    print(f\"   ç½®ä¿¡åŒºé—´: [{row['confidence_lower']:.4f}, {row['confidence_upper']:.4f}] (å®½åº¦: {ci_width:.4f})\")\n",
    "    print(f\"   ç¨³å®šæ€§: {row['stability_score']:.4f}\")\n",
    "    print()\n",
    "\n",
    "print(\"âœ… ç‰¹å¾é‡è¦æ€§åˆ†æå®Œæˆï¼å¯ä»¥åœ¨å…¶ä»–åˆ†æä¸­ä½¿ç”¨ `importance_dict` å˜é‡\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cd9cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_feature_importanc = final_validation_results['shap_result']['feature_importance'] \n",
    "shap_feature_importanc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97a1468",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_validation_results['shap_result']['feature_names']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb33339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. æå– shap_values æ•°ç»„ï¼Œè®¡ç®—ç»å¯¹å€¼å¹¶æŒ‰ç‰¹å¾æ±‚å‡å€¼\n",
    "shap_importance = final_validation_results['shap_result']['feature_importance']   # é•¿åº¦ä¸º n_features\n",
    "shap_features = final_validation_results['shap_result']['feature_names']  \n",
    "# 2. æ„å»ºæ–°çš„ DataFrame æˆ–åˆå¹¶åˆ°å·²æœ‰ DataFrame\n",
    "shap_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'shap_importance': shap_feature_importanc\n",
    "})\n",
    "shap_df\n",
    "# å¦‚æœä½ å·²æœ‰ importance_dfï¼Œåš mergeï¼š\n",
    "final_importance_df = final_importance_df.merge(shap_df, on='feature', how='left')\n",
    "final_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53967fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®é™…ç½®ä¿¡åŒºé—´åˆ†æå·¥å…·\n",
    "# =====================\n",
    "\n",
    "def analyze_confidence_intervals(importance_df):\n",
    "    \"\"\"\n",
    "    åˆ†æå®é™…æ•°æ®çš„ç½®ä¿¡åŒºé—´å¹¶æä¾›å»ºè®®\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ğŸ” æ‚¨çš„æ•°æ®ç½®ä¿¡åŒºé—´åˆ†æ\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # è®¡ç®—ç½®ä¿¡åŒºé—´å®½åº¦\n",
    "    importance_df['ci_width'] = importance_df['confidence_upper'] - importance_df['confidence_lower']\n",
    "    #ç›¸å¯¹åŒºé—´å®½åº¦\n",
    "    importance_df['ci_width']= importance_df['ci_width'] / (importance_df['combined_importance'].abs() + 1e-8)\n",
    "    # åˆ†ç±»ç‰¹å¾\n",
    "    high_confidence = importance_df[importance_df['ci_width'] <= 0.02]\n",
    "    medium_confidence = importance_df[(importance_df['ci_width'] > 0.02) & \n",
    "                                    (importance_df['ci_width'] <= 0.15)]\n",
    "    low_confidence = importance_df[importance_df['ci_width'] > 0.15]\n",
    "    \n",
    "    print(f\"ä¿¡åº¦åˆ†ç±»ç»“æœ:\")\n",
    "    print(f\" é«˜ç½®ä¿¡åº¦ç‰¹å¾: {len(high_confidence)}ä¸ª (å®½åº¦ â‰¤ 0.02)\")\n",
    "    print(f\" ä¸­ç­‰ç½®ä¿¡åº¦ç‰¹å¾: {len(medium_confidence)}ä¸ª (å®½åº¦ 0.02-0.15)\")\n",
    "    print(f\" ä½ç½®ä¿¡åº¦ç‰¹å¾: {len(low_confidence)}ä¸ª (å®½åº¦ > 0.15)\")\n",
    "    \n",
    "    print(f\"\\nğŸ† æœ€å¯ä¿¡çš„Top 10ç‰¹å¾ (ç½®ä¿¡åŒºé—´æœ€çª„):\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    # æŒ‰ç½®ä¿¡åŒºé—´å®½åº¦æ’åºï¼Œæ‰¾å‡ºæœ€å¯ä¿¡çš„ç‰¹å¾\n",
    "    most_reliable = importance_df.nsmallest(10, 'ci_width')\n",
    "    \n",
    "    for i, (_, row) in enumerate(most_reliable.iterrows(), 1):\n",
    "        print(f\"{i}. {row['feature']}\")\n",
    "        print(f\"   é‡è¦æ€§: {row['combined_importance']:.4f}\")\n",
    "        print(f\"   ç½®ä¿¡åŒºé—´: [{row['confidence_lower']:.4f}, {row['confidence_upper']:.4f}]\")\n",
    "        print(f\"   åŒºé—´å®½åº¦: {row['ci_width']:.4f} âœ…\")\n",
    "        print()\n",
    "    \n",
    "    if len(low_confidence) > 0:\n",
    "        print(f\"éœ€è¦æ³¨æ„çš„ä½ç½®ä¿¡åº¦ç‰¹å¾:\")\n",
    "        print(\"-\" * 35)\n",
    "        \n",
    "        for i, (_, row) in enumerate(low_confidence.head(3).iterrows(), 1):\n",
    "            print(f\"{i}. {row['feature']}\")\n",
    "            print(f\"   é‡è¦æ€§: {row['combined_importance']:.4f}\")\n",
    "            print(f\"   ç½®ä¿¡åŒºé—´: [{row['confidence_lower']:.4f}, {row['confidence_upper']:.4f}]\")\n",
    "            print(f\"   åŒºé—´å®½åº¦: {row['ci_width']:.4f}\")\n",
    "            print(f\"   â†’ å»ºè®®: è¿™ä¸ªç‰¹å¾çš„é‡è¦æ€§ä¸ç¨³å®šï¼Œä½¿ç”¨æ—¶éœ€è°¨æ…\")\n",
    "            print()\n",
    "    \n",
    "    # ç»¼åˆå»ºè®®\n",
    "    print(f\"ç»¼åˆå»ºè®®:\")\n",
    "    print(\"-\" * 15)\n",
    "    \n",
    "    reliable_important = importance_df[\n",
    "        (importance_df['combined_importance'] > 0.5) & \n",
    "        (importance_df['ci_width'] <= 0.05)\n",
    "    ]\n",
    "    \n",
    "    if len(reliable_important) > 0:\n",
    "        print(f\"æ¨èæ ¸å¿ƒç‰¹å¾ ({len(reliable_important)}ä¸ª): é‡è¦æ€§é«˜ä¸”å¯ä¿¡åº¦é«˜\")\n",
    "        for _, row in reliable_important.head(3).iterrows():\n",
    "            print(f\"   â€¢ {row['feature']}\")\n",
    "    \n",
    "    unreliable_features = importance_df[importance_df['ci_width'] > 0.1]\n",
    "    if len(unreliable_features) > 0:\n",
    "        print(f\"å»ºè®®é‡æ–°è¯„ä¼° ({len(unreliable_features)}ä¸ª): ç½®ä¿¡åŒºé—´è¿‡å®½\")\n",
    "        print(f\"   â†’ å¯èƒ½éœ€è¦æ›´å¤šæ•°æ®æˆ–ç‰¹å¾å·¥ç¨‹ä¼˜åŒ–\")\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "def create_confidence_summary_table(importance_df):\n",
    "    \"\"\"\n",
    "    åˆ›å»ºç½®ä¿¡åº¦æ±‡æ€»è¡¨\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"ç½®ä¿¡åº¦æ±‡æ€»è¡¨\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # é€‰æ‹©å…³é”®åˆ—å¹¶é‡å‘½å\n",
    "    summary_cols = ['feature', 'combined_importance', 'confidence_lower', \n",
    "                   'confidence_upper', 'ci_width', 'stability_score']\n",
    "    \n",
    "    summary_df = importance_df[summary_cols].head(10).copy()\n",
    "    \n",
    "    # é‡å‘½ååˆ—\n",
    "    summary_df.columns = ['ç‰¹å¾åç§°', 'ç»¼åˆé‡è¦æ€§', 'ç½®ä¿¡ä¸‹é™', 'ç½®ä¿¡ä¸Šé™', \n",
    "                         'åŒºé—´å®½åº¦', 'ç¨³å®šæ€§å¾—åˆ†']\n",
    "    \n",
    "    # æ·»åŠ å¯ä¿¡åº¦è¯„çº§\n",
    "    def get_confidence_rating(width):\n",
    "        if width <= 0.02:\n",
    "            return \" é«˜\"\n",
    "        elif width <= 0.15:\n",
    "            return \" ä¸­\"\n",
    "        else:\n",
    "            return \" ä½\"\n",
    "    \n",
    "    summary_df['å¯ä¿¡åº¦'] = summary_df['åŒºé—´å®½åº¦'].apply(get_confidence_rating)\n",
    "    \n",
    "    # æ ¼å¼åŒ–æ•°å€¼\n",
    "    for col in ['ç»¼åˆé‡è¦æ€§', 'ç½®ä¿¡ä¸‹é™', 'ç½®ä¿¡ä¸Šé™', 'åŒºé—´å®½åº¦', 'ç¨³å®šæ€§å¾—åˆ†']:\n",
    "        summary_df[col] = summary_df[col].round(4)\n",
    "    \n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "# æ£€æŸ¥æ˜¯å¦æœ‰importanceç»“æœå¯ä»¥åˆ†æ\n",
    "try:\n",
    "    if 'final_importance_df' in locals():\n",
    "        print(\"ğŸš€ åˆ†ææ‚¨çš„å®é™…ç‰¹å¾é‡è¦æ€§ç½®ä¿¡åŒºé—´...\")\n",
    "        \n",
    "        # åˆ†æç½®ä¿¡åŒºé—´\n",
    "        analyzed_df = analyze_confidence_intervals(final_importance_df)\n",
    "        \n",
    "        # åˆ›å»ºæ±‡æ€»è¡¨\n",
    "        summary_table = create_confidence_summary_table(analyzed_df)\n",
    "        \n",
    "    else:\n",
    "        print(\" è¯·å…ˆè¿è¡Œç‰¹å¾é‡è¦æ€§åˆ†æä»£ç ä»¥è·å¾— final_importance_df\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}\")\n",
    "    print(\" è¯·ç¡®ä¿å·²ç»è¿è¡Œäº†ç‰¹å¾é‡è¦æ€§åˆ†æçš„ä»£ç \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dd8143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»˜åˆ¶æœ€å¯ä¿¡çš„Top 10ç‰¹å¾å›¾è¡¨\n",
    "# ============================\n",
    "\n",
    "def plot_most_reliable_top10_features(importance_df):\n",
    "    \"\"\"\n",
    "    ç»˜åˆ¶æœ€å¯ä¿¡çš„Top 10ç‰¹å¾çš„è¯¦ç»†å›¾è¡¨\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ç»˜åˆ¶æœ€å¯ä¿¡çš„Top 10ç‰¹å¾...\")\n",
    "    \n",
    "    # è®¡ç®—ç½®ä¿¡åŒºé—´å®½åº¦\n",
    "    if 'ci_width' not in importance_df.columns:\n",
    "        importance_df['ci_width'] = importance_df['confidence_upper'] - importance_df['confidence_lower']\n",
    "        importance_df['ci_width']=  (importance_df['confidence_upper'] - importance_df['confidence_lower'])/ (importance_df['combined_importance'].abs() + 1e-8)\n",
    "    # æŒ‰shapé‡è¦æ€§æ’åºï¼Œé€‰æ‹©æœ€å¯ä¿¡çš„Top 10\n",
    "    importance_df['shap_importance']\n",
    "    most_reliable_top10 = importance_df.nsmallest(10, 'shap_importance').copy()\n",
    "    \n",
    "    # åˆ›å»ºå¤§å›¾è¡¨\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "    \n",
    "    # è®¾ç½®é¢œè‰²æ–¹æ¡ˆ\n",
    "    colors = plt.cm.RdYlGn(np.linspace(0.3, 1.0, 10))  # ç»¿è‰²ç³»è¡¨ç¤ºå¯ä¿¡åº¦é«˜\n",
    "    \n",
    "    # 1. ç‰¹å¾é‡è¦æ€§æ’åºï¼ˆå¸¦ç½®ä¿¡åŒºé—´ï¼‰\n",
    "    ax1 = axes[0, 0]\n",
    "    y_pos = np.arange(len(most_reliable_top10))\n",
    "    \n",
    "    # ç»˜åˆ¶æ¡å½¢å›¾\n",
    "    bars = ax1.barh(y_pos, most_reliable_top10['combined_importance'], \n",
    "                   color=colors, alpha=0.8, height=0.6)\n",
    "    \n",
    "    # ç»˜åˆ¶ç½®ä¿¡åŒºé—´\n",
    "    for i, (_, row) in enumerate(most_reliable_top10.iterrows()):\n",
    "        # æ ‡æ³¨ç½®ä¿¡åŒºé—´å®½åº¦\n",
    "        ax1.text(row['combined_importance'] + 0.002, i, \n",
    "                f'{row[\"ci_width\"]:.4f}', \n",
    "                verticalalignment='center', fontsize=9, \n",
    "                bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"white\", alpha=0.7))\n",
    "    \n",
    "    ax1.set_yticks(y_pos)\n",
    "    ax1.set_yticklabels(most_reliable_top10['feature'], fontsize=11)\n",
    "    ax1.set_xlabel('ç»¼åˆé‡è¦æ€§å¾—åˆ†', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('SHAPTop 10ç‰¹å¾é‡è¦æ€§æ’åº(è¡¨ç¤º95%ç½®ä¿¡åŒºé—´å®½åº¦,è¶Šå°è¶Šå¯ä¿¡)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_xlim(0, max(most_reliable_top10['combined_importance']) * 1.2)\n",
    "    \n",
    "    # 2. ç½®ä¿¡åŒºé—´å®½åº¦æ¯”è¾ƒ\n",
    "    ax2 = axes[0, 1]\n",
    "    \n",
    "    bars2 = ax2.bar(range(len(most_reliable_top10)), most_reliable_top10['ci_width'], \n",
    "                   color=colors, alpha=0.8)\n",
    "    \n",
    "    ax2.set_xticks(range(len(most_reliable_top10)))\n",
    "    ax2.set_xticklabels([f'ç‰¹å¾{i+1}' for i in range(len(most_reliable_top10))], \n",
    "                       rotation=45, ha='right')\n",
    "    ax2.set_ylabel('ç½®ä¿¡åŒºé—´å®½åº¦', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Top 10ç‰¹å¾çš„ç½®ä¿¡åŒºé—´å®½åº¦(è¶Šå°è¡¨ç¤ºè¶Šå¯ä¿¡)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # åœ¨æ¯ä¸ªæŸ±å­ä¸Šæ ‡æ³¨æ•°å€¼\n",
    "    for i, (bar, width) in enumerate(zip(bars2, most_reliable_top10['ci_width'])):\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.0005, \n",
    "                f'{width:.4f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # æ·»åŠ åˆ†ç•Œçº¿ï¼ˆå¯ä¿¡åº¦æ ‡å‡†ï¼‰\n",
    "    ax2.axhline(y=0.02, color='green', linestyle='--', alpha=0.7, linewidth=2,\n",
    "               label='é«˜å¯ä¿¡åº¦çº¿ (< 0.02)')\n",
    "    ax2.axhline(y=0.05, color='orange', linestyle='--', alpha=0.7, linewidth=2,\n",
    "               label='ä¸­ç­‰å¯ä¿¡åº¦çº¿ (< 0.05)')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # 3. ç¨³å®šæ€§å¾—åˆ†å¯¹æ¯”\n",
    "    ax3 = axes[1, 0]\n",
    "    \n",
    "    bars3 = ax3.bar(range(len(most_reliable_top10)), most_reliable_top10['stability_score'], \n",
    "                   color=colors, alpha=0.8)\n",
    "    \n",
    "    ax3.set_xticks(range(len(most_reliable_top10)))\n",
    "    ax3.set_xticklabels([f'ç‰¹å¾{i+1}' for i in range(len(most_reliable_top10))], \n",
    "                       rotation=45, ha='right')\n",
    "    ax3.set_ylabel('ç¨³å®šæ€§å¾—åˆ†', fontsize=12, fontweight='bold')\n",
    "    ax3.set_title('Top 10ç‰¹å¾çš„ç¨³å®šæ€§å¾—åˆ†(è¶Šé«˜è¡¨ç¤ºè¶Šç¨³å®š)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.set_ylim(0, 1.1)\n",
    "    \n",
    "    # åœ¨æ¯ä¸ªæŸ±å­ä¸Šæ ‡æ³¨æ•°å€¼\n",
    "    for i, (bar, score) in enumerate(zip(bars3, most_reliable_top10['stability_score'])):\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "                f'{score:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # 4. ç»¼åˆè¯„ä¼°é›·è¾¾å›¾é£æ ¼çš„æ•£ç‚¹å›¾\n",
    "    ax4 = axes[1, 1]\n",
    "    \n",
    "    # æ•£ç‚¹å›¾ï¼šé‡è¦æ€§ vs å¯ä¿¡åº¦ï¼ˆç”¨ç½®ä¿¡åŒºé—´å®½åº¦çš„å€’æ•°è¡¨ç¤ºï¼‰\n",
    "    reliability_score = 1 / (most_reliable_top10['ci_width'] + 0.001)  # é¿å…é™¤é›¶\n",
    "    \n",
    "    scatter = ax4.scatter(most_reliable_top10['combined_importance'], \n",
    "                         reliability_score,\n",
    "                         c=most_reliable_top10['stability_score'],\n",
    "                         s=200, alpha=0.8, cmap='RdYlGn', edgecolors='black')\n",
    "    \n",
    "    # æ·»åŠ ç‰¹å¾åç§°æ ‡æ³¨\n",
    "    for i, (_, row) in enumerate(most_reliable_top10.iterrows()):\n",
    "        ax4.annotate(f'ç‰¹å¾{i+1}', \n",
    "                    (row['combined_importance'], reliability_score.iloc[i]),\n",
    "                    xytext=(5, 5), textcoords='offset points',\n",
    "                    fontsize=10, fontweight='bold')\n",
    "    \n",
    "    ax4.set_xlabel('ç»¼åˆé‡è¦æ€§å¾—åˆ†', fontsize=12, fontweight='bold')\n",
    "    ax4.set_ylabel('å¯ä¿¡åº¦å¾—åˆ† (1/ç½®ä¿¡åŒºé—´å®½åº¦)', fontsize=12, fontweight='bold')\n",
    "    ax4.set_title('ç‰¹å¾é‡è¦æ€§ vs å¯ä¿¡åº¦åˆ†æ(é¢œè‰²è¡¨ç¤ºç¨³å®šæ€§ï¼Œè¶Šç»¿è¶Šç¨³å®š)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # æ·»åŠ é¢œè‰²æ¡\n",
    "    cbar = plt.colorbar(scatter, ax=ax4)\n",
    "    cbar.set_label('ç¨³å®šæ€§å¾—åˆ†', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # è¾“å‡ºç‰¹å¾å¯¹ç…§è¡¨\n",
    "    print(\"\\\\n ç‰¹å¾ç¼–å·å¯¹ç…§è¡¨:\")\n",
    "    print(\"=\" * 60)\n",
    "    for i, (_, row) in enumerate(most_reliable_top10.iterrows(), 1):\n",
    "        print(f\"ç‰¹å¾{i}: {row['feature']}\")\n",
    "    \n",
    "    print(\"\\\\n æœ€å¯ä¿¡Top 10ç‰¹å¾ç»Ÿè®¡:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"å¹³å‡é‡è¦æ€§å¾—åˆ†: {most_reliable_top10['combined_importance'].mean():.4f}\")\n",
    "    print(f\"å¹³å‡ç½®ä¿¡åŒºé—´å®½åº¦: {most_reliable_top10['ci_width'].mean():.4f}\")\n",
    "    print(f\"å¹³å‡ç¨³å®šæ€§å¾—åˆ†: {most_reliable_top10['stability_score'].mean():.4f}\")\n",
    "    \n",
    "    high_confidence_count = len(most_reliable_top10[most_reliable_top10['ci_width'] <= 0.02])\n",
    "    print(f\"\\\\né«˜å¯ä¿¡åº¦ç‰¹å¾æ•°é‡: {high_confidence_count}/10\")\n",
    "    print(f\"å¯ä¿¡åº¦ä¼˜ç§€ç‡: {high_confidence_count/10*100:.1f}%\")\n",
    "    \n",
    "    return most_reliable_top10\n",
    "\n",
    "# æ‰§è¡Œç»˜å›¾å‡½æ•°\n",
    "try:\n",
    "    if 'final_importance_df' in locals():\n",
    "        print(\" å¼€å§‹ç»˜åˆ¶æœ€å¯ä¿¡çš„Top 10ç‰¹å¾å›¾è¡¨...\")\n",
    "        \n",
    "        # ç»˜åˆ¶å›¾è¡¨\n",
    "        top10_reliable = plot_most_reliable_top10_features(final_importance_df)\n",
    "        \n",
    "        print(\"\\\\n å›¾è¡¨ç»˜åˆ¶å®Œæˆï¼\")\n",
    "        \n",
    "    else:\n",
    "        print(\"  è¯·å…ˆè¿è¡Œç‰¹å¾é‡è¦æ€§åˆ†æä»£ç ä»¥è·å¾— final_importance_df\")\n",
    "        print(\" è¿è¡Œé¡ºåºï¼šç‰¹å¾é‡è¦æ€§åˆ†æ â†’ ç½®ä¿¡åŒºé—´åˆ†æ â†’ ç»˜åˆ¶å›¾è¡¨\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"ç»˜å›¾è¿‡ç¨‹ä¸­å‡ºé”™: {e}\")\n",
    "    print(\" è¯·ç¡®ä¿å·²ç»è¿è¡Œäº†ç‰¹å¾é‡è¦æ€§åˆ†æçš„ä»£ç \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde520e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ä½¿ç”¨æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bbfb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰é›†æˆé¢„æµ‹å™¨ç±» (å¿…é¡»åœ¨åŠ è½½æ¨¡å‹å‰å®šä¹‰ï¼Œä»¥æ”¯æŒpickleåºåˆ—åŒ–)\n",
    "# ================================================================\n",
    "\n",
    "class EnsemblePredictor:\n",
    "    \"\"\"\n",
    "    é›†æˆé¢„æµ‹å™¨ç±» - ç”¨äºåŠ è½½å’Œä½¿ç”¨è®­ç»ƒå¥½çš„å¤šä¸ªé€»è¾‘å›å½’æ¨¡å‹\n",
    "    \"\"\"\n",
    "    def __init__(self, models, feature_names, threshold_strategies):\n",
    "        self.models = models  # åŒ…å«modelå’Œscalerçš„åˆ—è¡¨\n",
    "        self.feature_names = feature_names\n",
    "        self.threshold_strategies = threshold_strategies\n",
    "        self.n_models = len(models)\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"é¢„æµ‹æ¦‚ç‡ï¼ˆé›†æˆå¹³å‡ï¼‰\"\"\"\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X[self.feature_names].values\n",
    "        \n",
    "        all_probas = []\n",
    "        for model_info in self.models:\n",
    "            X_scaled = model_info['scaler'].transform(X)\n",
    "            proba = model_info['model'].predict_proba(X_scaled)[:, 1]\n",
    "            all_probas.append(proba)\n",
    "        \n",
    "        return np.mean(all_probas, axis=0)\n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        \"\"\"é¢„æµ‹ç±»åˆ«\"\"\"\n",
    "        probas = self.predict_proba(X)\n",
    "        return (probas >= threshold).astype(int)\n",
    "    \n",
    "    def predict_with_strategy(self, X, strategy_name):\n",
    "        \"\"\"ä½¿ç”¨ç‰¹å®šç­–ç•¥é¢„æµ‹\"\"\"\n",
    "        probas = self.predict_proba(X)\n",
    "        \n",
    "        strategy_thresholds = {\n",
    "            'æœ€é«˜å¬å›ç‡ç­–ç•¥': self.threshold_strategies[0][1]['threshold'],\n",
    "            'æœ€é«˜F1ç­–ç•¥': self.threshold_strategies[1][1]['threshold'],\n",
    "            'æœ€é«˜ç²¾ç¡®ç‡ç­–ç•¥': self.threshold_strategies[2][1]['threshold'],\n",
    "            'ä¸šåŠ¡å¹³è¡¡ç­–ç•¥': self.threshold_strategies[3][1]['threshold']\n",
    "        }\n",
    "        \n",
    "        threshold = strategy_thresholds.get(strategy_name, 0.5)\n",
    "        return (probas >= threshold).astype(int), probas\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        \"\"\"è·å–ç‰¹å¾åç§°\"\"\"\n",
    "        return self.feature_names\n",
    "    \n",
    "    def get_model_info(self):\n",
    "        \"\"\"è·å–æ¨¡å‹ä¿¡æ¯\"\"\"\n",
    "        return {\n",
    "            'n_models': self.n_models,\n",
    "            'feature_names': self.feature_names,\n",
    "            'available_strategies': ['æœ€é«˜å¬å›ç‡ç­–ç•¥', 'æœ€é«˜F1ç­–ç•¥', 'æœ€é«˜ç²¾ç¡®ç‡ç­–ç•¥', 'ä¸šåŠ¡å¹³è¡¡ç­–ç•¥']\n",
    "        }\n",
    "\n",
    "print(\"âœ… EnsemblePredictor ç±»å®šä¹‰å®Œæˆï¼Œæ”¯æŒpickleåºåˆ—åŒ–\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ada1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. å¯¼å…¥å¿…è¦çš„åº“\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"âœ… åº“å¯¼å…¥å®Œæˆ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712aa73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹\n",
    "# æ³¨æ„ï¼šä¿®æ”¹ä¸ºæ‚¨å®é™…çš„æ¨¡å‹è·¯å¾„\n",
    "\n",
    "try:\n",
    "    # è¯·ä¿®æ”¹ä¸ºæ‚¨å®é™…çš„æ¨¡å‹æ–‡ä»¶è·¯å¾„\n",
    "    model_path = ''\n",
    "    if os.path.exists(model_path):\n",
    "        # ä½¿ç”¨joblibåŠ è½½æ¨¡å‹ï¼ˆæ¨èæ–¹å¼ï¼‰\n",
    "        trained_model = joblib.load(model_path)\n",
    "        print(f\"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}\")\n",
    "        print(f\"ğŸ“Š æ¨¡å‹ä¿¡æ¯: {trained_model.get_model_info()}\")\n",
    "    else:\n",
    "        print(f\"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}\")\n",
    "        raise FileNotFoundError(f\"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}\")\n",
    "    print(f\"ğŸ’¡ å¯èƒ½åŸå› ï¼š\")\n",
    "    print(f\"   1. æ¨¡å‹æ–‡ä»¶è·¯å¾„ä¸æ­£ç¡®\")\n",
    "    print(f\"   2. éœ€è¦å…ˆè¿è¡ŒEnsemblePredictorç±»å®šä¹‰\")\n",
    "    print(f\"   3. æ¨¡å‹æ–‡ä»¶ç‰ˆæœ¬ä¸å…¼å®¹\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3a4145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¬¬ä¸€éƒ¨åˆ†ï¼šæ•°æ®é¢„å¤„ç†ä¸ç‰¹å¾å·¥ç¨‹ï¼ˆé’ˆå¯¹ä¸å¹³è¡¡æ ·æœ¬ä¼˜åŒ–ï¼‰\n",
    "# =================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d94b97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. æ¨¡å‹é¢„æµ‹\n",
    "# é¢„æµ‹è½¬åŒ–æ¦‚ç‡\n",
    "try:\n",
    "    # ä½¿ç”¨EnsemblePredictorçš„é¢„æµ‹æ–¹æ³•\n",
    "    prediction_probabilities = trained_model.predict_proba(X_new)\n",
    "    print(f\"âœ… ä½¿ç”¨é›†æˆæ¨¡å‹é¢„æµ‹å®Œæˆ\")\n",
    "    print(f\"ğŸ¯ æ¨¡å‹åŒ…å« {trained_model.n_models} ä¸ªå­æ¨¡å‹\")\n",
    "    print(f\"ğŸ“Š ä½¿ç”¨ç‰¹å¾: {trained_model.get_feature_names()}\")\n",
    "    print(f\"âœ… é¢„æµ‹å®Œæˆï¼Œé¢„æµ‹äº†{len(prediction_probabilities)}ä¸ªç”¨æˆ·çš„è½¬åŒ–æ¦‚ç‡\")\n",
    "    print(f\"ğŸ“Š æ¦‚ç‡èŒƒå›´: {prediction_probabilities.min():.3f} - {prediction_probabilities.max():.3f}\")\n",
    "    print(f\"ğŸ“Š å¹³å‡æ¦‚ç‡: {prediction_probabilities.mean():.3f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ é¢„æµ‹å¤±è´¥: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a03806",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_new_data=df\n",
    "# 7. å‡†å¤‡Excelè¾“å‡ºæ•°æ®\n",
    "# åˆ›å»ºè¯¦ç»†çš„ç”¨æˆ·æ¦‚ç‡è¡¨\n",
    "user_probability_table = pd.DataFrame({\n",
    "    'ç”¨æˆ·ID': processed_new_data['åŠ å¯†æ‰‹æœºå·ç '],\n",
    "    'è½¬åŒ–æ¦‚ç‡': prediction_probabilities,\n",
    "    'æ¦‚ç‡ç™¾åˆ†æ¯”': (prediction_probabilities * 100).round(1),\n",
    "})\n",
    "final_output_df = user_probability_table\n",
    "\n",
    "print(f\"âœ… æ•°æ®æ•´ç†å®Œæˆï¼Œå‡†å¤‡ä¿å­˜Excelæ–‡ä»¶\")\n",
    "# å°† final_output_df å’Œ df é€šè¿‡â€œåŠ å¯†æ‰‹æœºå·â€è¿æ¥\n",
    "merged_df = final_output_df.merge(\n",
    "    df, \n",
    "    left_on='ç”¨æˆ·ID', \n",
    "    right_on='åŠ å¯†æ‰‹æœºå·ç ', \n",
    "    how='left'  # or 'inner' ifåªä¿ç•™äº¤é›†\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2c7d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.drop(columns=[\"ç”¨æˆ·ID\"], inplace=True)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ef1804",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_excel('å…¨é‡é¢„æµ‹ç»“æœf2ä¼˜åŒ–100æ¬¡.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8ef38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280821a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# å‡è®¾ df å·²ç»å­˜åœ¨ï¼Œä¸”å«æœ‰ \"è½¬åŒ–æ¦‚ç‡\" åˆ—\n",
    "thresholds = np.arange(0, 1, 0.1)\n",
    "\n",
    "results = {\n",
    "    'threshold': [],\n",
    "    'count': [],\n",
    "    'proportion': []\n",
    "}\n",
    "\n",
    "total = len(df)\n",
    "\n",
    "for t in thresholds:\n",
    "    count = (df['è½¬åŒ–æ¦‚ç‡'] >= t).sum()\n",
    "    proportion = count / total\n",
    "    results['threshold'].append(t)\n",
    "    results['count'].append(count)\n",
    "    results['proportion'].append(proportion)\n",
    "\n",
    "result_df = pd.DataFrame(results)\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186c7c62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
